{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 76, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/db.ts"],"sourcesContent":["import { Pool } from 'pg';\r\nimport * as dotenv from 'dotenv';\r\n\r\ndotenv.config({ path: '.env.local' });\r\ndotenv.config({ path: '.env' });\r\n\r\nconsole.log('Initializing DB pool with:', process.env.DATABASE_URL);\r\n\r\nconst pool = new Pool({\r\n    connectionString: process.env.DATABASE_URL || 'postgresql://postgres:postgres@localhost:5432/search_engine',\r\n    ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,\r\n});\r\n\r\nexport default pool;\r\n"],"names":[],"mappings":";;;;AAAA;AACA;;;;;;;AAEA,iJAAa,CAAC;IAAE,MAAM;AAAa;AACnC,iJAAa,CAAC;IAAE,MAAM;AAAO;AAE7B,QAAQ,GAAG,CAAC,8BAA8B,QAAQ,GAAG,CAAC,YAAY;AAElE,MAAM,OAAO,IAAI,4GAAI,CAAC;IAClB,kBAAkB,QAAQ,GAAG,CAAC,YAAY,IAAI;IAC9C,KAAK,sCAAwC,0BAAgC;AACjF;uCAEe"}},
    {"offset": {"line": 107, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/services/search-service.ts"],"sourcesContent":["import pool from '../db';\r\n\r\nexport interface SearchParams {\r\n    query: string;\r\n    page?: number;\r\n    pageSize?: number;\r\n    filters?: {\r\n        language?: string;\r\n        dateRange?: {\r\n            start?: string;\r\n            end?: string;\r\n        };\r\n        site?: string;\r\n    };\r\n}\r\n\r\nexport interface SearchResult {\r\n    doc_id: string;\r\n    url: string;\r\n    title: string;\r\n    snippet: string;\r\n    score: number;\r\n    highlights: string[];\r\n    metadata: {\r\n        author?: string;\r\n        published_date?: string;\r\n        language?: string;\r\n    };\r\n}\r\n\r\nexport interface SearchResponse {\r\n    query: {\r\n        original: string;\r\n        corrected?: string;\r\n        intent?: string;\r\n    };\r\n    results: SearchResult[];\r\n    total_results: number;\r\n    page: number;\r\n    page_size: number;\r\n    query_time_ms: number;\r\n    suggestions: string[];\r\n}\r\n\r\nexport class SearchService {\r\n    async search(params: SearchParams): Promise<SearchResponse> {\r\n        const startTime = Date.now();\r\n        const { query, page = 1, pageSize = 10 } = params;\r\n        const offset = (page - 1) * pageSize;\r\n\r\n        // Handle single character/variable searches with pattern matching\r\n        const isSingleChar = query.trim().length === 1;\r\n        \r\n        let sql;\r\n        let queryParams;\r\n\r\n        if (isSingleChar) {\r\n            // For single character searches, use pattern matching instead of full-text search\r\n            const searchPattern = `%${query.trim()}%`;\r\n            sql = `\r\n                WITH ranked_docs AS (\r\n                    SELECT \r\n                        doc_id,\r\n                        url,\r\n                        title,\r\n                        meta_description,\r\n                        body,\r\n                        pagerank,\r\n                        crawl_timestamp,\r\n                        language,\r\n                        -- Simple relevance score for single character matches\r\n                        CASE \r\n                            WHEN title ILIKE $1 THEN 3.0\r\n                            WHEN meta_description ILIKE $1 THEN 2.0\r\n                            WHEN body ILIKE $1 THEN 1.0\r\n                            ELSE 0.5\r\n                        END as rank\r\n                    FROM documents\r\n                    WHERE \r\n                        title ILIKE $1 OR \r\n                        meta_description ILIKE $1 OR \r\n                        body ILIKE $1\r\n                ),\r\n                total_count AS (\r\n                    SELECT COUNT(*) as count FROM ranked_docs\r\n                )\r\n                SELECT \r\n                    rd.*,\r\n                    tc.count as total_results,\r\n                    -- Simple highlighting for pattern matches\r\n                    CASE \r\n                        WHEN title ILIKE $1 THEN regexp_replace(title, '(' || $2 || ')', '<em>\\\\1</em>', 'gi')\r\n                        ELSE title\r\n                    END as title_highlight,\r\n                    CASE \r\n                        WHEN body ILIKE $1 THEN regexp_replace(substring(body, 1, 500), '(' || $2 || ')', '<em>\\\\1</em>', 'gi')\r\n                        ELSE substring(body, 1, 500)\r\n                    END as body_highlight\r\n                FROM ranked_docs rd, total_count tc\r\n                ORDER BY rank DESC, pagerank DESC\r\n                LIMIT $3 OFFSET $4\r\n            `;\r\n            queryParams = [searchPattern, query.trim(), pageSize, offset];\r\n        } else {\r\n            // PostgreSQL Full-Text Search for longer queries\r\n            // We use websearch_to_tsquery for advanced syntax support (quotes, or, -negation)\r\n            // We search across title, meta_description, and body with different weights\r\n            sql = `\r\n                WITH search_query AS (\r\n                    SELECT websearch_to_tsquery('english', $1) as query\r\n                ),\r\n                ranked_docs AS (\r\n                    SELECT \r\n                        doc_id,\r\n                        url,\r\n                        title,\r\n                        meta_description,\r\n                        body,\r\n                        pagerank,\r\n                        crawl_timestamp,\r\n                        language,\r\n                        -- Rank calculation: (Title A-weight) + (Meta B-weight) + (Body C-weight)\r\n                        ts_rank_cd(\r\n                            setweight(to_tsvector('english', title), 'A') ||\r\n                            setweight(to_tsvector('english', coalesce(meta_description, '')), 'B') ||\r\n                            setweight(to_tsvector('english', coalesce(body, '')), 'C'),\r\n                            (SELECT query FROM search_query)\r\n                        ) as rank\r\n                    FROM documents\r\n                    WHERE \r\n                        (\r\n                            setweight(to_tsvector('english', title), 'A') ||\r\n                            setweight(to_tsvector('english', coalesce(meta_description, '')), 'B') ||\r\n                            setweight(to_tsvector('english', coalesce(body, '')), 'C')\r\n                        ) @@ (SELECT query FROM search_query)\r\n                ),\r\n                total_count AS (\r\n                    SELECT COUNT(*) as count FROM ranked_docs\r\n                )\r\n                SELECT \r\n                    rd.*,\r\n                    tc.count as total_results,\r\n                    ts_headline('english', rd.body, (SELECT query FROM search_query), \r\n                        'StartSel=<em>, StopSel=</em>, MaxWords=35, MinWords=15, ShortWord=3, HighlightAll=FALSE, MaxFragments=1, FragmentDelimiter=\"...\"'\r\n                    ) as body_highlight,\r\n                    ts_headline('english', rd.title, (SELECT query FROM search_query), \r\n                        'StartSel=<em>, StopSel=</em>, HighlightAll=FALSE'\r\n                    ) as title_highlight\r\n                FROM ranked_docs rd, total_count tc\r\n                ORDER BY rank DESC, pagerank DESC\r\n                LIMIT $2 OFFSET $3\r\n            `;\r\n            queryParams = [query, pageSize, offset];\r\n        }\r\n\r\n        try {\r\n            console.log(`Executing ${isSingleChar ? 'single character' : 'full-text'} search for query: \"${query}\"`);\r\n            const result = await pool.query(sql, queryParams);\r\n            console.log(`SQL executed. Rows: ${result.rows.length}`);\r\n\r\n            const totalResults = result.rows.length > 0 ? parseInt(result.rows[0].total_results, 10) : 0;\r\n\r\n            const searchResults: SearchResult[] = result.rows.map((row: any) => ({\r\n                doc_id: row.doc_id,\r\n                url: row.url,\r\n                title: row.title,\r\n                snippet: isSingleChar \r\n                    ? (row.body_highlight || row.meta_description || row.body || '').substring(0, 200) + '...'\r\n                    : (row.body_highlight || row.meta_description || ''),\r\n                score: parseFloat(row.rank) || 0,\r\n                highlights: [\r\n                    row.title_highlight,\r\n                    row.body_highlight\r\n                ].filter(Boolean),\r\n                metadata: {\r\n                    language: row.language,\r\n                    published_date: row.crawl_timestamp,\r\n                },\r\n            }));\r\n\r\n            const endTime = Date.now();\r\n\r\n            // Log the search event\r\n            this.logSearchEvent(query, totalResults, endTime - startTime);\r\n\r\n            return {\r\n                query: {\r\n                    original: query,\r\n                },\r\n                results: searchResults,\r\n                total_results: totalResults,\r\n                page,\r\n                page_size: pageSize,\r\n                query_time_ms: endTime - startTime,\r\n                suggestions: [],\r\n            };\r\n        } catch (error) {\r\n            console.error('Search error:', error);\r\n            throw error;\r\n        }\r\n    }\r\n\r\n    private async logSearchEvent(query: string, resultCount: number, executionTime: number) {\r\n        try {\r\n            const sql = `\r\n                INSERT INTO search_events (query_text, result_count, execution_time_ms)\r\n                VALUES ($1, $2, $3)\r\n            `;\r\n            await pool.query(sql, [query, resultCount, executionTime]);\r\n        } catch (err) {\r\n            console.error('Failed to log search event:', err);\r\n        }\r\n    }\r\n\r\n    async suggest(query: string, limit: number = 10): Promise<string[]> {\r\n        const sql = `\r\n            SELECT query_text \r\n            FROM query_suggestions \r\n            WHERE query_text ILIKE $1 \r\n            ORDER BY frequency DESC \r\n            LIMIT $2\r\n        `;\r\n        try {\r\n            const result = await pool.query(sql, [`${query}%`, limit]);\r\n            return result.rows.map((row: any) => row.query_text);\r\n        } catch (error) {\r\n            console.error('Suggestion error:', error);\r\n            return [];\r\n        }\r\n    }\r\n}\r\n\r\nexport const searchService = new SearchService();\r\n"],"names":[],"mappings":";;;;;;AAAA;;;;;;AA4CO,MAAM;IACT,MAAM,OAAO,MAAoB,EAA2B;QACxD,MAAM,YAAY,KAAK,GAAG;QAC1B,MAAM,EAAE,KAAK,EAAE,OAAO,CAAC,EAAE,WAAW,EAAE,EAAE,GAAG;QAC3C,MAAM,SAAS,CAAC,OAAO,CAAC,IAAI;QAE5B,kEAAkE;QAClE,MAAM,eAAe,MAAM,IAAI,GAAG,MAAM,KAAK;QAE7C,IAAI;QACJ,IAAI;QAEJ,IAAI,cAAc;YACd,kFAAkF;YAClF,MAAM,gBAAgB,CAAC,CAAC,EAAE,MAAM,IAAI,GAAG,CAAC,CAAC;YACzC,MAAM,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YA0CP,CAAC;YACD,cAAc;gBAAC;gBAAe,MAAM,IAAI;gBAAI;gBAAU;aAAO;QACjE,OAAO;YACH,iDAAiD;YACjD,kFAAkF;YAClF,4EAA4E;YAC5E,MAAM,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YA4CP,CAAC;YACD,cAAc;gBAAC;gBAAO;gBAAU;aAAO;QAC3C;QAEA,IAAI;YACA,QAAQ,GAAG,CAAC,CAAC,UAAU,EAAE,eAAe,qBAAqB,YAAY,oBAAoB,EAAE,MAAM,CAAC,CAAC;YACvG,MAAM,SAAS,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;YACrC,QAAQ,GAAG,CAAC,CAAC,oBAAoB,EAAE,OAAO,IAAI,CAAC,MAAM,EAAE;YAEvD,MAAM,eAAe,OAAO,IAAI,CAAC,MAAM,GAAG,IAAI,SAAS,OAAO,IAAI,CAAC,EAAE,CAAC,aAAa,EAAE,MAAM;YAE3F,MAAM,gBAAgC,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,MAAa,CAAC;oBACjE,QAAQ,IAAI,MAAM;oBAClB,KAAK,IAAI,GAAG;oBACZ,OAAO,IAAI,KAAK;oBAChB,SAAS,eACH,CAAC,IAAI,cAAc,IAAI,IAAI,gBAAgB,IAAI,IAAI,IAAI,IAAI,EAAE,EAAE,SAAS,CAAC,GAAG,OAAO,QAClF,IAAI,cAAc,IAAI,IAAI,gBAAgB,IAAI;oBACrD,OAAO,WAAW,IAAI,IAAI,KAAK;oBAC/B,YAAY;wBACR,IAAI,eAAe;wBACnB,IAAI,cAAc;qBACrB,CAAC,MAAM,CAAC;oBACT,UAAU;wBACN,UAAU,IAAI,QAAQ;wBACtB,gBAAgB,IAAI,eAAe;oBACvC;gBACJ,CAAC;YAED,MAAM,UAAU,KAAK,GAAG;YAExB,uBAAuB;YACvB,IAAI,CAAC,cAAc,CAAC,OAAO,cAAc,UAAU;YAEnD,OAAO;gBACH,OAAO;oBACH,UAAU;gBACd;gBACA,SAAS;gBACT,eAAe;gBACf;gBACA,WAAW;gBACX,eAAe,UAAU;gBACzB,aAAa,EAAE;YACnB;QACJ,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,iBAAiB;YAC/B,MAAM;QACV;IACJ;IAEA,MAAc,eAAe,KAAa,EAAE,WAAmB,EAAE,aAAqB,EAAE;QACpF,IAAI;YACA,MAAM,MAAM,CAAC;;;YAGb,CAAC;YACD,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;gBAAC;gBAAO;gBAAa;aAAc;QAC7D,EAAE,OAAO,KAAK;YACV,QAAQ,KAAK,CAAC,+BAA+B;QACjD;IACJ;IAEA,MAAM,QAAQ,KAAa,EAAE,QAAgB,EAAE,EAAqB;QAChE,MAAM,MAAM,CAAC;;;;;;QAMb,CAAC;QACD,IAAI;YACA,MAAM,SAAS,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;gBAAC,GAAG,MAAM,CAAC,CAAC;gBAAE;aAAM;YACzD,OAAO,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,MAAa,IAAI,UAAU;QACvD,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,qBAAqB;YACnC,OAAO,EAAE;QACb;IACJ;AACJ;AAEO,MAAM,gBAAgB,IAAI"}},
    {"offset": {"line": 512, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/config/elasticsearch/index-mappings.json"],"sourcesContent":["{\"settings\":{\"number_of_shards\":64,\"number_of_replicas\":2,\"refresh_interval\":\"30s\",\"index\":{\"codec\":\"best_compression\",\"max_result_window\":10000},\"analysis\":{\"analyzer\":{\"custom_analyzer\":{\"type\":\"custom\",\"tokenizer\":\"standard\",\"filter\":[\"lowercase\",\"porter_stem\",\"stop\",\"asciifolding\"]},\"ngram_analyzer\":{\"type\":\"custom\",\"tokenizer\":\"standard\",\"filter\":[\"lowercase\",\"ngram_filter\"]}},\"filter\":{\"ngram_filter\":{\"type\":\"ngram\",\"min_gram\":2,\"max_gram\":15}}}},\"mappings\":{\"properties\":{\"url\":{\"type\":\"keyword\"},\"canonical_url\":{\"type\":\"keyword\"},\"title\":{\"type\":\"text\",\"analyzer\":\"custom_analyzer\",\"fields\":{\"raw\":{\"type\":\"keyword\"},\"ngram\":{\"type\":\"text\",\"analyzer\":\"ngram_analyzer\"}},\"term_vector\":\"with_positions_offsets\"},\"body\":{\"type\":\"text\",\"analyzer\":\"custom_analyzer\",\"term_vector\":\"with_positions_offsets\",\"store\":false},\"meta_description\":{\"type\":\"text\",\"analyzer\":\"custom_analyzer\"},\"anchor_texts\":{\"type\":\"text\",\"analyzer\":\"custom_analyzer\"},\"headings\":{\"type\":\"text\",\"analyzer\":\"custom_analyzer\"},\"doc_length\":{\"type\":\"integer\"},\"pagerank\":{\"type\":\"float\"},\"language\":{\"type\":\"keyword\"},\"domain\":{\"type\":\"keyword\"},\"crawl_timestamp\":{\"type\":\"date\"},\"content_hash\":{\"type\":\"keyword\"},\"inbound_links\":{\"type\":\"integer\"},\"outbound_links\":{\"type\":\"integer\"},\"structured_data\":{\"type\":\"object\",\"enabled\":true}}}}"],"names":[],"mappings":"AAAA"}},
    {"offset": {"line": 512, "column": 1344}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 516, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/services/elasticsearch-service.ts"],"sourcesContent":["import { Client } from '@elastic/elasticsearch';\r\n\r\nclass ElasticsearchService {\r\n    private client: Client;\r\n    private indexName = 'search-documents';\r\n\r\n    constructor() {\r\n        this.client = new Client({\r\n            nodes: process.env.ELASTICSEARCH_NODES?.split(',') || ['http://localhost:9200'],\r\n            maxRetries: 5,\r\n            requestTimeout: 60000,\r\n            sniffOnStart: true,\r\n        });\r\n    }\r\n\r\n    async createIndex() {\r\n        const exists = await this.client.indices.exists({ index: this.indexName });\r\n\r\n        if (!exists) {\r\n            const mappings = require('../../config/elasticsearch/index-mappings.json');\r\n            await this.client.indices.create({\r\n                index: this.indexName,\r\n                body: mappings,\r\n            });\r\n            console.log(`Created index: ${this.indexName}`);\r\n        }\r\n    }\r\n\r\n    async indexDocument(doc: any) {\r\n        return await this.client.index({\r\n            index: this.indexName,\r\n            id: doc.doc_id,\r\n            document: {\r\n                url: doc.url,\r\n                canonical_url: doc.canonical_url,\r\n                title: doc.title,\r\n                body: doc.body,\r\n                meta_description: doc.meta_description,\r\n                anchor_texts: doc.anchor_texts || [],\r\n                headings: doc.headings || [],\r\n                doc_length: doc.body_length,\r\n                pagerank: doc.pagerank || 0,\r\n                language: doc.language || 'en',\r\n                domain: new URL(doc.url).hostname,\r\n                crawl_timestamp: doc.crawl_timestamp,\r\n                content_hash: doc.content_hash,\r\n                inbound_links: doc.inbound_links || 0,\r\n                outbound_links: doc.outbound_links || 0,\r\n                structured_data: doc.structured_data || [],\r\n            },\r\n        });\r\n    }\r\n\r\n    async bulkIndex(docs: any[]) {\r\n        const operations = docs.flatMap(doc => [\r\n            { index: { _index: this.indexName, _id: doc.doc_id } },\r\n            {\r\n                url: doc.url,\r\n                canonical_url: doc.canonical_url,\r\n                title: doc.title,\r\n                body: doc.body,\r\n                meta_description: doc.meta_description,\r\n                anchor_texts: doc.anchor_texts || [],\r\n                headings: doc.headings || [],\r\n                doc_length: doc.body_length,\r\n                pagerank: doc.pagerank || 0,\r\n                language: doc.language || 'en',\r\n                domain: new URL(doc.url).hostname,\r\n                crawl_timestamp: doc.crawl_timestamp,\r\n                content_hash: doc.content_hash,\r\n                inbound_links: doc.inbound_links || 0,\r\n                outbound_links: doc.outbound_links || 0,\r\n                structured_data: doc.structured_data || [],\r\n            },\r\n        ]);\r\n\r\n        const result = await this.client.bulk({ operations, refresh: false });\r\n\r\n        if (result.errors) {\r\n            const erroredDocuments = result.items.filter((item: any) => item.index?.error);\r\n            console.error('Bulk indexing errors:', erroredDocuments);\r\n        }\r\n\r\n        return result;\r\n    }\r\n\r\n    async search(query: string, options: any = {}) {\r\n        const {\r\n            page = 1,\r\n            pageSize = 10,\r\n            filters = {},\r\n        } = options;\r\n\r\n        const from = (page - 1) * pageSize;\r\n\r\n        // Build Elasticsearch query\r\n        const mustClauses: any[] = [\r\n            {\r\n                multi_match: {\r\n                    query,\r\n                    fields: [\r\n                        'title^3',           // Title is most important\r\n                        'meta_description^2', // Description is next\r\n                        'body',              // Body content\r\n                        'headings^2',        // Headings are important\r\n                        'anchor_texts^1.5',  // Anchor texts have some weight\r\n                    ],\r\n                    type: 'best_fields',\r\n                    operator: 'or',\r\n                    fuzziness: 'AUTO',\r\n                },\r\n            },\r\n        ];\r\n\r\n        // Add filters\r\n        const filterClauses: any[] = [];\r\n        if (filters.language) {\r\n            filterClauses.push({ term: { language: filters.language } });\r\n        }\r\n        if (filters.site) {\r\n            filterClauses.push({ term: { domain: filters.site } });\r\n        }\r\n        if (filters.dateRange) {\r\n            filterClauses.push({\r\n                range: {\r\n                    crawl_timestamp: {\r\n                        gte: filters.dateRange.start,\r\n                        lte: filters.dateRange.end,\r\n                    },\r\n                },\r\n            });\r\n        }\r\n\r\n        const searchBody = {\r\n            query: {\r\n                function_score: {\r\n                    query: {\r\n                        bool: {\r\n                            must: mustClauses,\r\n                            filter: filterClauses,\r\n                        },\r\n                    },\r\n                    functions: [\r\n                        {\r\n                            // Boost by PageRank\r\n                            field_value_factor: {\r\n                                field: 'pagerank',\r\n                                factor: 1.2,\r\n                                modifier: 'log1p',\r\n                                missing: 0,\r\n                            },\r\n                        },\r\n                        {\r\n                            // Boost by inbound links\r\n                            field_value_factor: {\r\n                                field: 'inbound_links',\r\n                                factor: 0.1,\r\n                                modifier: 'log1p',\r\n                                missing: 0,\r\n                            },\r\n                        },\r\n                        {\r\n                            // Boost recent documents slightly\r\n                            gauss: {\r\n                                crawl_timestamp: {\r\n                                    origin: 'now',\r\n                                    scale: '30d',\r\n                                    decay: 0.5,\r\n                                },\r\n                            },\r\n                        },\r\n                    ],\r\n                    score_mode: 'sum',\r\n                    boost_mode: 'multiply',\r\n                },\r\n            },\r\n            from,\r\n            size: pageSize,\r\n            highlight: {\r\n                fields: {\r\n                    title: { number_of_fragments: 0 },\r\n                    body: { number_of_fragments: 1, fragment_size: 150 },\r\n                    meta_description: { number_of_fragments: 1 },\r\n                },\r\n                pre_tags: ['<em>'],\r\n                post_tags: ['</em>'],\r\n            },\r\n            _source: [\r\n                'url',\r\n                'title',\r\n                'meta_description',\r\n                'body',\r\n                'domain',\r\n                'language',\r\n                'pagerank',\r\n                'crawl_timestamp',\r\n                'inbound_links',\r\n                'outbound_links',\r\n            ],\r\n        };\r\n\r\n        try {\r\n            const result = await this.client.search({\r\n                index: this.indexName,\r\n                body: searchBody,\r\n            });\r\n\r\n            return {\r\n                hits: result.hits.hits,\r\n                total: typeof result.hits.total === 'number'\r\n                    ? result.hits.total\r\n                    : result.hits.total?.value || 0,\r\n            };\r\n        } catch (error) {\r\n            console.error('Elasticsearch search error:', error);\r\n            throw error;\r\n        }\r\n    }\r\n\r\n    async getStats() {\r\n        try {\r\n            const health = await this.client.cluster.health();\r\n            const stats = await this.client.indices.stats({ index: this.indexName });\r\n\r\n            return {\r\n                index: stats.indices?.[this.indexName],\r\n                cluster: health,\r\n            };\r\n        } catch (error) {\r\n            console.error('Elasticsearch stats error:', error);\r\n            throw error;\r\n        }\r\n    }\r\n\r\n    async healthCheck(): Promise<boolean> {\r\n        try {\r\n            const health = await this.client.cluster.health();\r\n            return health.status === 'green' || health.status === 'yellow';\r\n        } catch (error) {\r\n            console.error('Elasticsearch health check failed:', error);\r\n            return false;\r\n        }\r\n    }\r\n}\r\n\r\nexport const elasticsearchService = new ElasticsearchService();\r\n"],"names":[],"mappings":";;;;AAAA;;AAEA,MAAM;IACM,OAAe;IACf,YAAY,mBAAmB;IAEvC,aAAc;QACV,IAAI,CAAC,MAAM,GAAG,IAAI,+JAAM,CAAC;YACrB,OAAO,QAAQ,GAAG,CAAC,mBAAmB,EAAE,MAAM,QAAQ;gBAAC;aAAwB;YAC/E,YAAY;YACZ,gBAAgB;YAChB,cAAc;QAClB;IACJ;IAEA,MAAM,cAAc;QAChB,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC;YAAE,OAAO,IAAI,CAAC,SAAS;QAAC;QAExE,IAAI,CAAC,QAAQ;YACT,MAAM;YACN,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC;gBAC7B,OAAO,IAAI,CAAC,SAAS;gBACrB,MAAM;YACV;YACA,QAAQ,GAAG,CAAC,CAAC,eAAe,EAAE,IAAI,CAAC,SAAS,EAAE;QAClD;IACJ;IAEA,MAAM,cAAc,GAAQ,EAAE;QAC1B,OAAO,MAAM,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC;YAC3B,OAAO,IAAI,CAAC,SAAS;YACrB,IAAI,IAAI,MAAM;YACd,UAAU;gBACN,KAAK,IAAI,GAAG;gBACZ,eAAe,IAAI,aAAa;gBAChC,OAAO,IAAI,KAAK;gBAChB,MAAM,IAAI,IAAI;gBACd,kBAAkB,IAAI,gBAAgB;gBACtC,cAAc,IAAI,YAAY,IAAI,EAAE;gBACpC,UAAU,IAAI,QAAQ,IAAI,EAAE;gBAC5B,YAAY,IAAI,WAAW;gBAC3B,UAAU,IAAI,QAAQ,IAAI;gBAC1B,UAAU,IAAI,QAAQ,IAAI;gBAC1B,QAAQ,IAAI,IAAI,IAAI,GAAG,EAAE,QAAQ;gBACjC,iBAAiB,IAAI,eAAe;gBACpC,cAAc,IAAI,YAAY;gBAC9B,eAAe,IAAI,aAAa,IAAI;gBACpC,gBAAgB,IAAI,cAAc,IAAI;gBACtC,iBAAiB,IAAI,eAAe,IAAI,EAAE;YAC9C;QACJ;IACJ;IAEA,MAAM,UAAU,IAAW,EAAE;QACzB,MAAM,aAAa,KAAK,OAAO,CAAC,CAAA,MAAO;gBACnC;oBAAE,OAAO;wBAAE,QAAQ,IAAI,CAAC,SAAS;wBAAE,KAAK,IAAI,MAAM;oBAAC;gBAAE;gBACrD;oBACI,KAAK,IAAI,GAAG;oBACZ,eAAe,IAAI,aAAa;oBAChC,OAAO,IAAI,KAAK;oBAChB,MAAM,IAAI,IAAI;oBACd,kBAAkB,IAAI,gBAAgB;oBACtC,cAAc,IAAI,YAAY,IAAI,EAAE;oBACpC,UAAU,IAAI,QAAQ,IAAI,EAAE;oBAC5B,YAAY,IAAI,WAAW;oBAC3B,UAAU,IAAI,QAAQ,IAAI;oBAC1B,UAAU,IAAI,QAAQ,IAAI;oBAC1B,QAAQ,IAAI,IAAI,IAAI,GAAG,EAAE,QAAQ;oBACjC,iBAAiB,IAAI,eAAe;oBACpC,cAAc,IAAI,YAAY;oBAC9B,eAAe,IAAI,aAAa,IAAI;oBACpC,gBAAgB,IAAI,cAAc,IAAI;oBACtC,iBAAiB,IAAI,eAAe,IAAI,EAAE;gBAC9C;aACH;QAED,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;YAAE;YAAY,SAAS;QAAM;QAEnE,IAAI,OAAO,MAAM,EAAE;YACf,MAAM,mBAAmB,OAAO,KAAK,CAAC,MAAM,CAAC,CAAC,OAAc,KAAK,KAAK,EAAE;YACxE,QAAQ,KAAK,CAAC,yBAAyB;QAC3C;QAEA,OAAO;IACX;IAEA,MAAM,OAAO,KAAa,EAAE,UAAe,CAAC,CAAC,EAAE;QAC3C,MAAM,EACF,OAAO,CAAC,EACR,WAAW,EAAE,EACb,UAAU,CAAC,CAAC,EACf,GAAG;QAEJ,MAAM,OAAO,CAAC,OAAO,CAAC,IAAI;QAE1B,4BAA4B;QAC5B,MAAM,cAAqB;YACvB;gBACI,aAAa;oBACT;oBACA,QAAQ;wBACJ;wBACA;wBACA;wBACA;wBACA;qBACH;oBACD,MAAM;oBACN,UAAU;oBACV,WAAW;gBACf;YACJ;SACH;QAED,cAAc;QACd,MAAM,gBAAuB,EAAE;QAC/B,IAAI,QAAQ,QAAQ,EAAE;YAClB,cAAc,IAAI,CAAC;gBAAE,MAAM;oBAAE,UAAU,QAAQ,QAAQ;gBAAC;YAAE;QAC9D;QACA,IAAI,QAAQ,IAAI,EAAE;YACd,cAAc,IAAI,CAAC;gBAAE,MAAM;oBAAE,QAAQ,QAAQ,IAAI;gBAAC;YAAE;QACxD;QACA,IAAI,QAAQ,SAAS,EAAE;YACnB,cAAc,IAAI,CAAC;gBACf,OAAO;oBACH,iBAAiB;wBACb,KAAK,QAAQ,SAAS,CAAC,KAAK;wBAC5B,KAAK,QAAQ,SAAS,CAAC,GAAG;oBAC9B;gBACJ;YACJ;QACJ;QAEA,MAAM,aAAa;YACf,OAAO;gBACH,gBAAgB;oBACZ,OAAO;wBACH,MAAM;4BACF,MAAM;4BACN,QAAQ;wBACZ;oBACJ;oBACA,WAAW;wBACP;4BACI,oBAAoB;4BACpB,oBAAoB;gCAChB,OAAO;gCACP,QAAQ;gCACR,UAAU;gCACV,SAAS;4BACb;wBACJ;wBACA;4BACI,yBAAyB;4BACzB,oBAAoB;gCAChB,OAAO;gCACP,QAAQ;gCACR,UAAU;gCACV,SAAS;4BACb;wBACJ;wBACA;4BACI,kCAAkC;4BAClC,OAAO;gCACH,iBAAiB;oCACb,QAAQ;oCACR,OAAO;oCACP,OAAO;gCACX;4BACJ;wBACJ;qBACH;oBACD,YAAY;oBACZ,YAAY;gBAChB;YACJ;YACA;YACA,MAAM;YACN,WAAW;gBACP,QAAQ;oBACJ,OAAO;wBAAE,qBAAqB;oBAAE;oBAChC,MAAM;wBAAE,qBAAqB;wBAAG,eAAe;oBAAI;oBACnD,kBAAkB;wBAAE,qBAAqB;oBAAE;gBAC/C;gBACA,UAAU;oBAAC;iBAAO;gBAClB,WAAW;oBAAC;iBAAQ;YACxB;YACA,SAAS;gBACL;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;aACH;QACL;QAEA,IAAI;YACA,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;gBACpC,OAAO,IAAI,CAAC,SAAS;gBACrB,MAAM;YACV;YAEA,OAAO;gBACH,MAAM,OAAO,IAAI,CAAC,IAAI;gBACtB,OAAO,OAAO,OAAO,IAAI,CAAC,KAAK,KAAK,WAC9B,OAAO,IAAI,CAAC,KAAK,GACjB,OAAO,IAAI,CAAC,KAAK,EAAE,SAAS;YACtC;QACJ,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,+BAA+B;YAC7C,MAAM;QACV;IACJ;IAEA,MAAM,WAAW;QACb,IAAI;YACA,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM;YAC/C,MAAM,QAAQ,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC;gBAAE,OAAO,IAAI,CAAC,SAAS;YAAC;YAEtE,OAAO;gBACH,OAAO,MAAM,OAAO,EAAE,CAAC,IAAI,CAAC,SAAS,CAAC;gBACtC,SAAS;YACb;QACJ,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,8BAA8B;YAC5C,MAAM;QACV;IACJ;IAEA,MAAM,cAAgC;QAClC,IAAI;YACA,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM;YAC/C,OAAO,OAAO,MAAM,KAAK,WAAW,OAAO,MAAM,KAAK;QAC1D,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,sCAAsC;YACpD,OAAO;QACX;IACJ;AACJ;AAEO,MAAM,uBAAuB,IAAI"}},
    {"offset": {"line": 778, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/services/cache-service.ts"],"sourcesContent":["// import Redis from 'ioredis'; // Disabled for No-Docker\r\n\r\nclass CacheService {\r\n    // private redis: Redis;\r\n    private localCache: Map<string, { value: any; expiry: number }>;\r\n    private readonly LOCAL_CACHE_TTL = 60 * 1000; // 1 minute\r\n\r\n    constructor() {\r\n        /*\r\n        this.redis = new Redis({\r\n            host: process.env.REDIS_HOST || 'localhost',\r\n            port: parseInt(process.env.REDIS_PORT || '6379'),\r\n            maxRetriesPerRequest: 3,\r\n            retryStrategy: (times) => {\r\n                const delay = Math.min(times * 50, 2000);\r\n                return delay;\r\n            },\r\n        });\r\n        */\r\n\r\n        this.localCache = new Map();\r\n\r\n        // Cleanup expired local cache entries\r\n        setInterval(() => {\r\n            const now = Date.now();\r\n            for (const [key, entry] of this.localCache.entries()) {\r\n                if (entry.expiry < now) {\r\n                    this.localCache.delete(key);\r\n                }\r\n            }\r\n        }, 60000); // Every minute\r\n    }\r\n\r\n    private getCacheKey(prefix: string, key: string): string {\r\n        return `${prefix}:${key}`;\r\n    }\r\n\r\n    async get<T>(prefix: string, key: string): Promise<T | null> {\r\n        const cacheKey = this.getCacheKey(prefix, key);\r\n\r\n        // L1: Check local cache\r\n        const localEntry = this.localCache.get(cacheKey);\r\n        if (localEntry && localEntry.expiry > Date.now()) {\r\n            return localEntry.value as T;\r\n        }\r\n\r\n        return null;\r\n    }\r\n\r\n    async set(prefix: string, key: string, value: any, ttl?: number): Promise<void> {\r\n        const cacheKey = this.getCacheKey(prefix, key);\r\n\r\n        // Update local cache\r\n        this.localCache.set(cacheKey, {\r\n            value,\r\n            expiry: Date.now() + (ttl ? ttl * 1000 : this.LOCAL_CACHE_TTL),\r\n        });\r\n    }\r\n\r\n    async delete(prefix: string, key: string): Promise<void> {\r\n        const cacheKey = this.getCacheKey(prefix, key);\r\n        this.localCache.delete(cacheKey);\r\n    }\r\n\r\n    async invalidatePattern(pattern: string): Promise<void> {\r\n        // Clear local cache entries matching pattern\r\n        for (const key of this.localCache.keys()) {\r\n            if (key.match(pattern)) {\r\n                this.localCache.delete(key);\r\n            }\r\n        }\r\n    }\r\n\r\n    // Rate limiting (Mocked)\r\n    async checkRateLimit(key: string, limit: number, window: number): Promise<boolean> {\r\n        return true; // Always allow\r\n    }\r\n\r\n    async disconnect(): Promise<void> {\r\n        // await this.redis.quit();\r\n    }\r\n}\r\n\r\nexport const cacheService = new CacheService();\r\n"],"names":[],"mappings":"AAAA,yDAAyD;;;;;AAEzD,MAAM;IACF,wBAAwB;IAChB,WAAwD;IAC/C,kBAAkB,KAAK,KAAK;IAE7C,aAAc;QACV;;;;;;;;;;QAUA,GAEA,IAAI,CAAC,UAAU,GAAG,IAAI;QAEtB,sCAAsC;QACtC,YAAY;YACR,MAAM,MAAM,KAAK,GAAG;YACpB,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,GAAI;gBAClD,IAAI,MAAM,MAAM,GAAG,KAAK;oBACpB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;gBAC3B;YACJ;QACJ,GAAG,QAAQ,eAAe;IAC9B;IAEQ,YAAY,MAAc,EAAE,GAAW,EAAU;QACrD,OAAO,GAAG,OAAO,CAAC,EAAE,KAAK;IAC7B;IAEA,MAAM,IAAO,MAAc,EAAE,GAAW,EAAqB;QACzD,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC,QAAQ;QAE1C,wBAAwB;QACxB,MAAM,aAAa,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;QACvC,IAAI,cAAc,WAAW,MAAM,GAAG,KAAK,GAAG,IAAI;YAC9C,OAAO,WAAW,KAAK;QAC3B;QAEA,OAAO;IACX;IAEA,MAAM,IAAI,MAAc,EAAE,GAAW,EAAE,KAAU,EAAE,GAAY,EAAiB;QAC5E,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC,QAAQ;QAE1C,qBAAqB;QACrB,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,UAAU;YAC1B;YACA,QAAQ,KAAK,GAAG,KAAK,CAAC,MAAM,MAAM,OAAO,IAAI,CAAC,eAAe;QACjE;IACJ;IAEA,MAAM,OAAO,MAAc,EAAE,GAAW,EAAiB;QACrD,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC,QAAQ;QAC1C,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;IAC3B;IAEA,MAAM,kBAAkB,OAAe,EAAiB;QACpD,6CAA6C;QAC7C,KAAK,MAAM,OAAO,IAAI,CAAC,UAAU,CAAC,IAAI,GAAI;YACtC,IAAI,IAAI,KAAK,CAAC,UAAU;gBACpB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;YAC3B;QACJ;IACJ;IAEA,yBAAyB;IACzB,MAAM,eAAe,GAAW,EAAE,KAAa,EAAE,MAAc,EAAoB;QAC/E,OAAO,MAAM,eAAe;IAChC;IAEA,MAAM,aAA4B;IAC9B,2BAA2B;IAC/B;AACJ;AAEO,MAAM,eAAe,IAAI"}},
    {"offset": {"line": 856, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/services/hybrid-search-service.ts"],"sourcesContent":["import { SearchParams, SearchResponse, SearchResult, searchService } from './search-service';\r\nimport { elasticsearchService } from './elasticsearch-service';\r\nimport { cacheService } from './cache-service';\r\nimport crypto from 'crypto';\r\n\r\n/**\r\n * Hybrid Search Service\r\n * Orchestrates search across multiple backends with fallback and caching\r\n * Priority: Cache → Elasticsearch → PostgreSQL\r\n */\r\n\r\nexport interface HybridSearchOptions extends SearchParams {\r\n  useCache?: boolean;\r\n  preferElasticsearch?: boolean;\r\n  timeout?: number;\r\n}\r\n\r\nexport class HybridSearchService {\r\n  private readonly CACHE_TTL = 300; // 5 minutes\r\n  private readonly SEARCH_TIMEOUT = 5000; // 5 seconds\r\n\r\n  /**\r\n   * Generate cache key for search query\r\n   */\r\n  private getCacheKey(params: SearchParams): string {\r\n    const normalized = {\r\n      query: params.query.toLowerCase().trim(),\r\n      page: params.page || 1,\r\n      pageSize: params.pageSize || 10,\r\n      filters: params.filters || {},\r\n    };\r\n    const hash = crypto.createHash('sha256').update(JSON.stringify(normalized)).digest('hex');\r\n    return `search:${hash}`;\r\n  }\r\n\r\n  /**\r\n   * Main search method with hybrid strategy\r\n   */\r\n  async search(params: HybridSearchOptions): Promise<SearchResponse> {\r\n    const startTime = Date.now();\r\n    const cacheKey = this.getCacheKey(params);\r\n    const useCache = params.useCache !== false;\r\n\r\n    try {\r\n      // Step 1: Try cache\r\n      if (useCache) {\r\n        const cached = await this.tryCache(cacheKey);\r\n        if (cached) {\r\n          console.log(`Cache hit for query: \"${params.query}\"`);\r\n          cached.query_time_ms = Date.now() - startTime;\r\n          return cached;\r\n        }\r\n      }\r\n\r\n      // Step 2: Try Elasticsearch (if configured and preferred)\r\n      if (params.preferElasticsearch && process.env.ENABLE_ELASTICSEARCH === 'true') {\r\n        try {\r\n          const esResult = await this.tryElasticsearch(params);\r\n          if (esResult) {\r\n            console.log(`Elasticsearch returned ${esResult.results.length} results`);\r\n\r\n            // Cache the result\r\n            if (useCache) {\r\n              await cacheService.set(cacheKey, esResult, this.CACHE_TTL).catch((err) => {\r\n                console.error('Failed to cache ES result:', err);\r\n              });\r\n            }\r\n\r\n            esResult.query_time_ms = Date.now() - startTime;\r\n            return esResult;\r\n          }\r\n        } catch (error) {\r\n          console.warn('Elasticsearch search failed, falling back to PostgreSQL:', error);\r\n        }\r\n      }\r\n\r\n      // Step 3: Fallback to PostgreSQL\r\n      console.log('Using PostgreSQL for search');\r\n      const pgResult = await searchService.search(params);\r\n\r\n      // Cache the result\r\n      if (useCache) {\r\n        await cacheService.set(cacheKey, pgResult, this.CACHE_TTL).catch((err) => {\r\n          console.error('Failed to cache PG result:', err);\r\n        });\r\n      }\r\n\r\n      pgResult.query_time_ms = Date.now() - startTime;\r\n      return pgResult;\r\n    } catch (error) {\r\n      console.error('All search backends failed:', error);\r\n      throw new Error('Search service temporarily unavailable');\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Try to get results from cache\r\n   */\r\n  private async tryCache(cacheKey: string): Promise<SearchResponse | null> {\r\n    try {\r\n      const cached = await cacheService.get<SearchResponse>('search', cacheKey);\r\n      return cached;\r\n    } catch (error) {\r\n      console.warn('Cache lookup failed:', error);\r\n      return null;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Try to get results from Elasticsearch\r\n   */\r\n  private async tryElasticsearch(params: SearchParams): Promise<SearchResponse | null> {\r\n    // Check if Elasticsearch is healthy\r\n    const isHealthy = await this.withTimeout(\r\n      elasticsearchService.healthCheck(),\r\n      2000\r\n    );\r\n\r\n    if (!isHealthy) {\r\n      console.log('Elasticsearch not healthy, skipping');\r\n      return null;\r\n    }\r\n\r\n    // Execute search with timeout\r\n    const esResponse = await this.withTimeout(\r\n      elasticsearchService.search(params.query, {\r\n        page: params.page,\r\n        pageSize: params.pageSize,\r\n        filters: params.filters,\r\n      }),\r\n      this.SEARCH_TIMEOUT\r\n    );\r\n\r\n    if (!esResponse || esResponse.hits.length === 0) {\r\n      return null;\r\n    }\r\n\r\n    // Transform Elasticsearch results to SearchResponse format\r\n    const results: SearchResult[] = esResponse.hits.map((hit: any) => {\r\n      const source = hit._source;\r\n      return {\r\n        doc_id: hit._id,\r\n        url: source.url,\r\n        title: source.title,\r\n        snippet: this.extractSnippet(hit, source),\r\n        score: hit._score || 0,\r\n        highlights: this.extractHighlights(hit),\r\n        metadata: {\r\n          author: source.author,\r\n          published_date: source.crawl_timestamp,\r\n          language: source.language,\r\n        },\r\n      };\r\n    });\r\n\r\n    return {\r\n      query: {\r\n        original: params.query,\r\n      },\r\n      results,\r\n      total_results: esResponse.total,\r\n      page: params.page || 1,\r\n      page_size: params.pageSize || 10,\r\n      query_time_ms: 0, // Will be set by caller\r\n      suggestions: [],\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Extract snippet from Elasticsearch hit\r\n   */\r\n  private extractSnippet(hit: any, source: any): string {\r\n    if (hit.highlight?.body) {\r\n      return hit.highlight.body[0];\r\n    }\r\n    if (hit.highlight?.meta_description) {\r\n      return hit.highlight.meta_description[0];\r\n    }\r\n    if (source.meta_description) {\r\n      return source.meta_description.substring(0, 200);\r\n    }\r\n    if (source.body) {\r\n      return source.body.substring(0, 200) + '...';\r\n    }\r\n    return '';\r\n  }\r\n\r\n  /**\r\n   * Extract highlights from Elasticsearch hit\r\n   */\r\n  private extractHighlights(hit: any): string[] {\r\n    const highlights: string[] = [];\r\n    if (hit.highlight) {\r\n      for (const field of Object.keys(hit.highlight)) {\r\n        highlights.push(...hit.highlight[field]);\r\n      }\r\n    }\r\n    return highlights;\r\n  }\r\n\r\n  /**\r\n   * Execute promise with timeout\r\n   */\r\n  private async withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {\r\n    return Promise.race([\r\n      promise,\r\n      new Promise<T>((_, reject) =>\r\n        setTimeout(() => reject(new Error('Operation timed out')), timeoutMs)\r\n      ),\r\n    ]);\r\n  }\r\n\r\n  /**\r\n   * Warm up cache with popular queries\r\n   */\r\n  async warmCache(queries: string[]): Promise<void> {\r\n    console.log(`Warming cache with ${queries.length} queries...`);\r\n    const promises = queries.map((query) =>\r\n      this.search({ query, page: 1, pageSize: 10, useCache: true }).catch((err) => {\r\n        console.error(`Failed to warm cache for query \"${query}\":`, err);\r\n      })\r\n    );\r\n    await Promise.all(promises);\r\n    console.log('Cache warming complete');\r\n  }\r\n\r\n  /**\r\n   * Invalidate cache for a query\r\n   */\r\n  async invalidateCache(params: SearchParams): Promise<void> {\r\n    const cacheKey = this.getCacheKey(params);\r\n    await cacheService.delete('search', cacheKey);\r\n  }\r\n\r\n  /**\r\n   * Get search backend health status\r\n   */\r\n  async getHealthStatus(): Promise<{\r\n    elasticsearch: boolean;\r\n    postgresql: boolean;\r\n    cache: boolean;\r\n  }> {\r\n    const [esHealth, pgHealth] = await Promise.all([\r\n      elasticsearchService.healthCheck().catch(() => false),\r\n      this.checkPostgresHealth().catch(() => false),\r\n    ]);\r\n\r\n    return {\r\n      elasticsearch: esHealth,\r\n      postgresql: pgHealth,\r\n      cache: true, // Local cache is always available\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Check PostgreSQL health\r\n   */\r\n  private async checkPostgresHealth(): Promise<boolean> {\r\n    try {\r\n      // Try a simple search\r\n      await searchService.search({ query: 'test', page: 1, pageSize: 1 });\r\n      return true;\r\n    } catch {\r\n      return false;\r\n    }\r\n  }\r\n}\r\n\r\nexport const hybridSearchService = new HybridSearchService();\r\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;;;;;;;;;AAcO,MAAM;IACM,YAAY,IAAI;IAChB,iBAAiB,KAAK;IAEvC;;GAEC,GACD,AAAQ,YAAY,MAAoB,EAAU;QAChD,MAAM,aAAa;YACjB,OAAO,OAAO,KAAK,CAAC,WAAW,GAAG,IAAI;YACtC,MAAM,OAAO,IAAI,IAAI;YACrB,UAAU,OAAO,QAAQ,IAAI;YAC7B,SAAS,OAAO,OAAO,IAAI,CAAC;QAC9B;QACA,MAAM,OAAO,gHAAM,CAAC,UAAU,CAAC,UAAU,MAAM,CAAC,KAAK,SAAS,CAAC,aAAa,MAAM,CAAC;QACnF,OAAO,CAAC,OAAO,EAAE,MAAM;IACzB;IAEA;;GAEC,GACD,MAAM,OAAO,MAA2B,EAA2B;QACjE,MAAM,YAAY,KAAK,GAAG;QAC1B,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC;QAClC,MAAM,WAAW,OAAO,QAAQ,KAAK;QAErC,IAAI;YACF,oBAAoB;YACpB,IAAI,UAAU;gBACZ,MAAM,SAAS,MAAM,IAAI,CAAC,QAAQ,CAAC;gBACnC,IAAI,QAAQ;oBACV,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,OAAO,KAAK,CAAC,CAAC,CAAC;oBACpD,OAAO,aAAa,GAAG,KAAK,GAAG,KAAK;oBACpC,OAAO;gBACT;YACF;YAEA,0DAA0D;YAC1D,IAAI,OAAO,mBAAmB,IAAI,QAAQ,GAAG,CAAC,oBAAoB,KAAK,QAAQ;gBAC7E,IAAI;oBACF,MAAM,WAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC;oBAC7C,IAAI,UAAU;wBACZ,QAAQ,GAAG,CAAC,CAAC,uBAAuB,EAAE,SAAS,OAAO,CAAC,MAAM,CAAC,QAAQ,CAAC;wBAEvE,mBAAmB;wBACnB,IAAI,UAAU;4BACZ,MAAM,qJAAY,CAAC,GAAG,CAAC,UAAU,UAAU,IAAI,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC;gCAChE,QAAQ,KAAK,CAAC,8BAA8B;4BAC9C;wBACF;wBAEA,SAAS,aAAa,GAAG,KAAK,GAAG,KAAK;wBACtC,OAAO;oBACT;gBACF,EAAE,OAAO,OAAO;oBACd,QAAQ,IAAI,CAAC,4DAA4D;gBAC3E;YACF;YAEA,iCAAiC;YACjC,QAAQ,GAAG,CAAC;YACZ,MAAM,WAAW,MAAM,uJAAa,CAAC,MAAM,CAAC;YAE5C,mBAAmB;YACnB,IAAI,UAAU;gBACZ,MAAM,qJAAY,CAAC,GAAG,CAAC,UAAU,UAAU,IAAI,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC;oBAChE,QAAQ,KAAK,CAAC,8BAA8B;gBAC9C;YACF;YAEA,SAAS,aAAa,GAAG,KAAK,GAAG,KAAK;YACtC,OAAO;QACT,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,+BAA+B;YAC7C,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,MAAc,SAAS,QAAgB,EAAkC;QACvE,IAAI;YACF,MAAM,SAAS,MAAM,qJAAY,CAAC,GAAG,CAAiB,UAAU;YAChE,OAAO;QACT,EAAE,OAAO,OAAO;YACd,QAAQ,IAAI,CAAC,wBAAwB;YACrC,OAAO;QACT;IACF;IAEA;;GAEC,GACD,MAAc,iBAAiB,MAAoB,EAAkC;QACnF,oCAAoC;QACpC,MAAM,YAAY,MAAM,IAAI,CAAC,WAAW,CACtC,qKAAoB,CAAC,WAAW,IAChC;QAGF,IAAI,CAAC,WAAW;YACd,QAAQ,GAAG,CAAC;YACZ,OAAO;QACT;QAEA,8BAA8B;QAC9B,MAAM,aAAa,MAAM,IAAI,CAAC,WAAW,CACvC,qKAAoB,CAAC,MAAM,CAAC,OAAO,KAAK,EAAE;YACxC,MAAM,OAAO,IAAI;YACjB,UAAU,OAAO,QAAQ;YACzB,SAAS,OAAO,OAAO;QACzB,IACA,IAAI,CAAC,cAAc;QAGrB,IAAI,CAAC,cAAc,WAAW,IAAI,CAAC,MAAM,KAAK,GAAG;YAC/C,OAAO;QACT;QAEA,2DAA2D;QAC3D,MAAM,UAA0B,WAAW,IAAI,CAAC,GAAG,CAAC,CAAC;YACnD,MAAM,SAAS,IAAI,OAAO;YAC1B,OAAO;gBACL,QAAQ,IAAI,GAAG;gBACf,KAAK,OAAO,GAAG;gBACf,OAAO,OAAO,KAAK;gBACnB,SAAS,IAAI,CAAC,cAAc,CAAC,KAAK;gBAClC,OAAO,IAAI,MAAM,IAAI;gBACrB,YAAY,IAAI,CAAC,iBAAiB,CAAC;gBACnC,UAAU;oBACR,QAAQ,OAAO,MAAM;oBACrB,gBAAgB,OAAO,eAAe;oBACtC,UAAU,OAAO,QAAQ;gBAC3B;YACF;QACF;QAEA,OAAO;YACL,OAAO;gBACL,UAAU,OAAO,KAAK;YACxB;YACA;YACA,eAAe,WAAW,KAAK;YAC/B,MAAM,OAAO,IAAI,IAAI;YACrB,WAAW,OAAO,QAAQ,IAAI;YAC9B,eAAe;YACf,aAAa,EAAE;QACjB;IACF;IAEA;;GAEC,GACD,AAAQ,eAAe,GAAQ,EAAE,MAAW,EAAU;QACpD,IAAI,IAAI,SAAS,EAAE,MAAM;YACvB,OAAO,IAAI,SAAS,CAAC,IAAI,CAAC,EAAE;QAC9B;QACA,IAAI,IAAI,SAAS,EAAE,kBAAkB;YACnC,OAAO,IAAI,SAAS,CAAC,gBAAgB,CAAC,EAAE;QAC1C;QACA,IAAI,OAAO,gBAAgB,EAAE;YAC3B,OAAO,OAAO,gBAAgB,CAAC,SAAS,CAAC,GAAG;QAC9C;QACA,IAAI,OAAO,IAAI,EAAE;YACf,OAAO,OAAO,IAAI,CAAC,SAAS,CAAC,GAAG,OAAO;QACzC;QACA,OAAO;IACT;IAEA;;GAEC,GACD,AAAQ,kBAAkB,GAAQ,EAAY;QAC5C,MAAM,aAAuB,EAAE;QAC/B,IAAI,IAAI,SAAS,EAAE;YACjB,KAAK,MAAM,SAAS,OAAO,IAAI,CAAC,IAAI,SAAS,EAAG;gBAC9C,WAAW,IAAI,IAAI,IAAI,SAAS,CAAC,MAAM;YACzC;QACF;QACA,OAAO;IACT;IAEA;;GAEC,GACD,MAAc,YAAe,OAAmB,EAAE,SAAiB,EAAc;QAC/E,OAAO,QAAQ,IAAI,CAAC;YAClB;YACA,IAAI,QAAW,CAAC,GAAG,SACjB,WAAW,IAAM,OAAO,IAAI,MAAM,yBAAyB;SAE9D;IACH;IAEA;;GAEC,GACD,MAAM,UAAU,OAAiB,EAAiB;QAChD,QAAQ,GAAG,CAAC,CAAC,mBAAmB,EAAE,QAAQ,MAAM,CAAC,WAAW,CAAC;QAC7D,MAAM,WAAW,QAAQ,GAAG,CAAC,CAAC,QAC5B,IAAI,CAAC,MAAM,CAAC;gBAAE;gBAAO,MAAM;gBAAG,UAAU;gBAAI,UAAU;YAAK,GAAG,KAAK,CAAC,CAAC;gBACnE,QAAQ,KAAK,CAAC,CAAC,gCAAgC,EAAE,MAAM,EAAE,CAAC,EAAE;YAC9D;QAEF,MAAM,QAAQ,GAAG,CAAC;QAClB,QAAQ,GAAG,CAAC;IACd;IAEA;;GAEC,GACD,MAAM,gBAAgB,MAAoB,EAAiB;QACzD,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC;QAClC,MAAM,qJAAY,CAAC,MAAM,CAAC,UAAU;IACtC;IAEA;;GAEC,GACD,MAAM,kBAIH;QACD,MAAM,CAAC,UAAU,SAAS,GAAG,MAAM,QAAQ,GAAG,CAAC;YAC7C,qKAAoB,CAAC,WAAW,GAAG,KAAK,CAAC,IAAM;YAC/C,IAAI,CAAC,mBAAmB,GAAG,KAAK,CAAC,IAAM;SACxC;QAED,OAAO;YACL,eAAe;YACf,YAAY;YACZ,OAAO;QACT;IACF;IAEA;;GAEC,GACD,MAAc,sBAAwC;QACpD,IAAI;YACF,sBAAsB;YACtB,MAAM,uJAAa,CAAC,MAAM,CAAC;gBAAE,OAAO;gBAAQ,MAAM;gBAAG,UAAU;YAAE;YACjE,OAAO;QACT,EAAE,OAAM;YACN,OAAO;QACT;IACF;AACF;AAEO,MAAM,sBAAsB,IAAI"}},
    {"offset": {"line": 1092, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/services/interaction-service.ts"],"sourcesContent":["import pool from '../db';\r\n\r\nexport interface SearchEvent {\r\n    user_id?: string;\r\n    session_id: string;\r\n    query: string;\r\n    result_count: number;\r\n    execution_time_ms: number;\r\n}\r\n\r\nexport interface ClickEvent {\r\n    search_event_id: string;\r\n    doc_id: string;\r\n    position: number;\r\n    user_id?: string;\r\n    session_id: string;\r\n}\r\n\r\nexport class InteractionService {\r\n    async logSearchEvent(event: SearchEvent): Promise<string> {\r\n        const sql = `\r\n            INSERT INTO search_events (\r\n                user_id, \r\n                session_id, \r\n                query_text, \r\n                result_count, \r\n                execution_time_ms\r\n            )\r\n            VALUES ($1, $2, $3, $4, $5)\r\n            RETURNING event_id\r\n        `;\r\n\r\n        try {\r\n            const result = await pool.query(sql, [\r\n                event.user_id || null,\r\n                event.session_id,\r\n                event.query,\r\n                event.result_count,\r\n                event.execution_time_ms\r\n            ]);\r\n            return result.rows[0].event_id;\r\n        } catch (error) {\r\n            console.error('Failed to log search event:', error);\r\n            return ''; // Fail gracefully\r\n        }\r\n    }\r\n\r\n    async logClickEvent(event: ClickEvent): Promise<string> {\r\n        const sql = `\r\n            INSERT INTO click_events (\r\n                search_event_id,\r\n                doc_id,\r\n                position\r\n            )\r\n            VALUES ($1, $2, $3)\r\n            RETURNING click_id\r\n        `;\r\n\r\n        try {\r\n            // Verify search_event_id exists to maintain referential integrity\r\n            // In a real high-volume system, we might skip this check or use a queue\r\n            if (event.search_event_id) {\r\n                const result = await pool.query(sql, [\r\n                    event.search_event_id,\r\n                    event.doc_id,\r\n                    event.position\r\n                ]);\r\n                return result.rows[0].click_id;\r\n            } else {\r\n                console.warn('Click event missing search_event_id, skipping insert');\r\n                return '';\r\n            }\r\n        } catch (error) {\r\n            console.error('Failed to log click event:', error);\r\n            return '';\r\n        }\r\n    }\r\n\r\n    async getUserHistory(userId: string, limit: number = 10) {\r\n        const sql = `\r\n            SELECT \r\n                se.query_text, \r\n                se.timestamp, \r\n                count(ce.click_id) as clicks\r\n            FROM search_events se\r\n            LEFT JOIN click_events ce ON se.event_id = ce.search_event_id\r\n            WHERE se.user_id = $1\r\n            GROUP BY se.event_id, se.query_text, se.timestamp\r\n            ORDER BY se.timestamp DESC\r\n            LIMIT $2\r\n        `;\r\n\r\n        try {\r\n            const result = await pool.query(sql, [userId, limit]);\r\n            return result.rows;\r\n        } catch (error) {\r\n            console.error('Failed to get user history:', error);\r\n            return [];\r\n        }\r\n    }\r\n}\r\n\r\nexport const interactionService = new InteractionService();\r\n"],"names":[],"mappings":";;;;;;AAAA;;;;;;AAkBO,MAAM;IACT,MAAM,eAAe,KAAkB,EAAmB;QACtD,MAAM,MAAM,CAAC;;;;;;;;;;QAUb,CAAC;QAED,IAAI;YACA,MAAM,SAAS,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;gBACjC,MAAM,OAAO,IAAI;gBACjB,MAAM,UAAU;gBAChB,MAAM,KAAK;gBACX,MAAM,YAAY;gBAClB,MAAM,iBAAiB;aAC1B;YACD,OAAO,OAAO,IAAI,CAAC,EAAE,CAAC,QAAQ;QAClC,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,+BAA+B;YAC7C,OAAO,IAAI,kBAAkB;QACjC;IACJ;IAEA,MAAM,cAAc,KAAiB,EAAmB;QACpD,MAAM,MAAM,CAAC;;;;;;;;QAQb,CAAC;QAED,IAAI;YACA,kEAAkE;YAClE,wEAAwE;YACxE,IAAI,MAAM,eAAe,EAAE;gBACvB,MAAM,SAAS,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;oBACjC,MAAM,eAAe;oBACrB,MAAM,MAAM;oBACZ,MAAM,QAAQ;iBACjB;gBACD,OAAO,OAAO,IAAI,CAAC,EAAE,CAAC,QAAQ;YAClC,OAAO;gBACH,QAAQ,IAAI,CAAC;gBACb,OAAO;YACX;QACJ,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,8BAA8B;YAC5C,OAAO;QACX;IACJ;IAEA,MAAM,eAAe,MAAc,EAAE,QAAgB,EAAE,EAAE;QACrD,MAAM,MAAM,CAAC;;;;;;;;;;;QAWb,CAAC;QAED,IAAI;YACA,MAAM,SAAS,MAAM,sHAAI,CAAC,KAAK,CAAC,KAAK;gBAAC;gBAAQ;aAAM;YACpD,OAAO,OAAO,IAAI;QACtB,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,+BAA+B;YAC7C,OAAO,EAAE;QACb;IACJ;AACJ;AAEO,MAAM,qBAAqB,IAAI"}},
    {"offset": {"line": 1215, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/metrics/prometheus.ts"],"sourcesContent":["import { register, Counter, Histogram, Gauge } from 'prom-client';\r\n\r\n// Query metrics\r\nexport const queryCounter = new Counter({\r\n    name: 'search_queries_total',\r\n    help: 'Total number of search queries',\r\n    labelNames: ['status', 'cache_hit'],\r\n});\r\n\r\nexport const queryLatency = new Histogram({\r\n    name: 'search_query_duration_seconds',\r\n    help: 'Search query latency in seconds',\r\n    labelNames: ['stage'],\r\n    buckets: [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5],\r\n});\r\n\r\nexport const queryResultCount = new Histogram({\r\n    name: 'search_query_results',\r\n    help: 'Number of results returned per query',\r\n    buckets: [0, 1, 10, 100, 1000, 10000],\r\n});\r\n\r\n// Indexing metrics\r\nexport const indexingCounter = new Counter({\r\n    name: 'documents_indexed_total',\r\n    help: 'Total number of documents indexed',\r\n    labelNames: ['status'],\r\n});\r\n\r\nexport const indexingLatency = new Histogram({\r\n    name: 'indexing_duration_seconds',\r\n    help: 'Document indexing latency in seconds',\r\n    buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],\r\n});\r\n\r\n// Crawler metrics\r\nexport const crawlCounter = new Counter({\r\n    name: 'urls_crawled_total',\r\n    help: 'Total number of URLs crawled',\r\n    labelNames: ['status'],\r\n});\r\n\r\nexport const crawlLatency = new Histogram({\r\n    name: 'crawl_duration_seconds',\r\n    help: 'URL crawl latency in seconds',\r\n    buckets: [0.1, 0.5, 1, 2, 5, 10, 30],\r\n});\r\n\r\nexport const crawlQueueSize = new Gauge({\r\n    name: 'crawl_queue_size',\r\n    help: 'Current size of the crawl queue',\r\n    labelNames: ['priority'],\r\n});\r\n\r\n// Cache metrics\r\nexport const cacheHitCounter = new Counter({\r\n    name: 'cache_hits_total',\r\n    help: 'Total number of cache hits',\r\n    labelNames: ['tier'],\r\n});\r\n\r\nexport const cacheMissCounter = new Counter({\r\n    name: 'cache_misses_total',\r\n    help: 'Total number of cache misses',\r\n    labelNames: ['tier'],\r\n});\r\n\r\n// System metrics\r\nexport const activeConnections = new Gauge({\r\n    name: 'active_connections',\r\n    help: 'Number of active connections',\r\n    labelNames: ['service'],\r\n});\r\n\r\nexport const errorCounter = new Counter({\r\n    name: 'errors_total',\r\n    help: 'Total number of errors',\r\n    labelNames: ['service', 'type'],\r\n});\r\n\r\n// Export metrics endpoint\r\nexport function getMetrics() {\r\n    return register.metrics();\r\n}\r\n\r\nexport { register };\r\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;AAGO,MAAM,eAAe,IAAI,oJAAO,CAAC;IACpC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;QAAU;KAAY;AACvC;AAEO,MAAM,eAAe,IAAI,sJAAS,CAAC;IACtC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAQ;IACrB,SAAS;QAAC;QAAM;QAAM;QAAK;QAAK;QAAK;QAAG;QAAG;KAAE;AACjD;AAEO,MAAM,mBAAmB,IAAI,sJAAS,CAAC;IAC1C,MAAM;IACN,MAAM;IACN,SAAS;QAAC;QAAG;QAAG;QAAI;QAAK;QAAM;KAAM;AACzC;AAGO,MAAM,kBAAkB,IAAI,oJAAO,CAAC;IACvC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAS;AAC1B;AAEO,MAAM,kBAAkB,IAAI,sJAAS,CAAC;IACzC,MAAM;IACN,MAAM;IACN,SAAS;QAAC;QAAM;QAAM;QAAK;QAAK;QAAG;QAAG;KAAE;AAC5C;AAGO,MAAM,eAAe,IAAI,oJAAO,CAAC;IACpC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAS;AAC1B;AAEO,MAAM,eAAe,IAAI,sJAAS,CAAC;IACtC,MAAM;IACN,MAAM;IACN,SAAS;QAAC;QAAK;QAAK;QAAG;QAAG;QAAG;QAAI;KAAG;AACxC;AAEO,MAAM,iBAAiB,IAAI,kJAAK,CAAC;IACpC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAW;AAC5B;AAGO,MAAM,kBAAkB,IAAI,oJAAO,CAAC;IACvC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAO;AACxB;AAEO,MAAM,mBAAmB,IAAI,oJAAO,CAAC;IACxC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAO;AACxB;AAGO,MAAM,oBAAoB,IAAI,kJAAK,CAAC;IACvC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;KAAU;AAC3B;AAEO,MAAM,eAAe,IAAI,oJAAO,CAAC;IACpC,MAAM;IACN,MAAM;IACN,YAAY;QAAC;QAAW;KAAO;AACnC;AAGO,SAAS;IACZ,OAAO,qJAAQ,CAAC,OAAO;AAC3B"}},
    {"offset": {"line": 1366, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/validation/schemas.ts"],"sourcesContent":["import { z } from 'zod';\r\n\r\n/**\r\n * Validation schemas for API request validation\r\n * Using Zod for type-safe runtime validation\r\n */\r\n\r\n// Search query validation\r\nexport const searchRequestSchema = z.object({\r\n  query: z\r\n    .string()\r\n    .trim()\r\n    .min(1, 'Query cannot be empty')\r\n    .max(500, 'Query too long (max 500 characters)')\r\n    .transform((val) => sanitizeQuery(val)),\r\n  page: z\r\n    .number()\r\n    .int()\r\n    .positive()\r\n    .max(100, 'Page number too high')\r\n    .default(1)\r\n    .optional(),\r\n  page_size: z\r\n    .number()\r\n    .int()\r\n    .positive()\r\n    .min(1)\r\n    .max(100, 'Page size too large')\r\n    .default(10)\r\n    .optional(),\r\n  filters: z\r\n    .object({\r\n      language: z.string().length(2).optional(),\r\n      site: z.string().url().or(z.string().regex(/^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/)).optional(),\r\n      dateRange: z\r\n        .object({\r\n          start: z.string().datetime().optional(),\r\n          end: z.string().datetime().optional(),\r\n        })\r\n        .optional(),\r\n    })\r\n    .optional(),\r\n  options: z\r\n    .object({\r\n      spell_correct: z.boolean().optional(),\r\n      exact_match: z.boolean().optional(),\r\n      safe_search: z.boolean().default(true).optional(),\r\n    })\r\n    .optional(),\r\n});\r\n\r\nexport type SearchRequest = z.infer<typeof searchRequestSchema>;\r\n\r\n// Suggestion query validation\r\nexport const suggestionRequestSchema = z.object({\r\n  q: z\r\n    .string()\r\n    .trim()\r\n    .min(1, 'Query must be at least 1 character')\r\n    .max(200, 'Query too long')\r\n    .transform((val) => sanitizeQuery(val)),\r\n  limit: z.number().int().positive().max(20).default(10).optional(),\r\n});\r\n\r\nexport type SuggestionRequest = z.infer<typeof suggestionRequestSchema>;\r\n\r\n// Click event validation\r\nexport const clickEventSchema = z.object({\r\n  search_event_id: z.string().uuid('Invalid search event ID'),\r\n  doc_id: z.string().uuid('Invalid document ID'),\r\n  position: z.number().int().positive().max(1000),\r\n  url: z.string().url('Invalid URL'),\r\n  query: z.string().max(500).optional(),\r\n});\r\n\r\nexport type ClickEvent = z.infer<typeof clickEventSchema>;\r\n\r\n// Admin crawl request validation\r\nexport const crawlRequestSchema = z.object({\r\n  urls: z\r\n    .array(z.string().url('Invalid URL'))\r\n    .min(1, 'At least one URL required')\r\n    .max(1000, 'Too many URLs (max 1000)'),\r\n  priority: z.enum(['low', 'normal', 'high']).default('normal').optional(),\r\n  respect_robots: z.boolean().default(true).optional(),\r\n});\r\n\r\nexport type CrawlRequest = z.infer<typeof crawlRequestSchema>;\r\n\r\n/**\r\n * Sanitizes search query to prevent injection attacks\r\n * Removes potentially dangerous characters while preserving search functionality\r\n */\r\nfunction sanitizeQuery(query: string): string {\r\n  // Remove null bytes\r\n  let sanitized = query.replace(/\\0/g, '');\r\n  \r\n  // Remove control characters except newline, carriage return, tab\r\n  sanitized = sanitized.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\r\n  \r\n  // Limit consecutive spaces\r\n  sanitized = sanitized.replace(/\\s+/g, ' ');\r\n  \r\n  // Remove leading/trailing whitespace\r\n  sanitized = sanitized.trim();\r\n  \r\n  // Remove potentially dangerous SQL patterns (defense in depth)\r\n  const dangerousPatterns = [\r\n    /;\\s*(drop|delete|insert|update|create|alter|exec|execute|script)/gi,\r\n    /--/g,\r\n    /\\/\\*/g,\r\n    /\\*\\//g,\r\n  ];\r\n  \r\n  for (const pattern of dangerousPatterns) {\r\n    sanitized = sanitized.replace(pattern, '');\r\n  }\r\n  \r\n  return sanitized;\r\n}\r\n\r\n/**\r\n * Sanitizes HTML content to prevent XSS attacks\r\n * Strips all HTML tags and converts special characters\r\n */\r\nexport function sanitizeHtml(html: string): string {\r\n  if (!html) return '';\r\n  \r\n  // Strip HTML tags\r\n  let sanitized = html.replace(/<[^>]*>/g, '');\r\n  \r\n  // Encode special characters\r\n  sanitized = sanitized\r\n    .replace(/&/g, '&amp;')\r\n    .replace(/</g, '&lt;')\r\n    .replace(/>/g, '&gt;')\r\n    .replace(/\"/g, '&quot;')\r\n    .replace(/'/g, '&#x27;')\r\n    .replace(/\\//g, '&#x2F;');\r\n  \r\n  return sanitized;\r\n}\r\n\r\n/**\r\n * Validates and sanitizes URLs\r\n */\r\nexport function sanitizeUrl(url: string): string {\r\n  try {\r\n    const parsed = new URL(url);\r\n    \r\n    // Only allow http and https protocols\r\n    if (!['http:', 'https:'].includes(parsed.protocol)) {\r\n      throw new Error('Invalid protocol');\r\n    }\r\n    \r\n    return parsed.toString();\r\n  } catch {\r\n    throw new Error('Invalid URL format');\r\n  }\r\n}\r\n\r\n/**\r\n * Rate limit check result\r\n */\r\nexport interface RateLimitCheck {\r\n  allowed: boolean;\r\n  remaining: number;\r\n  resetAt: Date;\r\n}\r\n\r\n/**\r\n * Error response structure\r\n */\r\nexport interface ErrorResponse {\r\n  error: {\r\n    code: string;\r\n    message: string;\r\n    details?: any;\r\n  };\r\n  request_id: string;\r\n  timestamp: string;\r\n}\r\n\r\n/**\r\n * Creates a standardized error response\r\n */\r\nexport function createErrorResponse(\r\n  code: string,\r\n  message: string,\r\n  details?: any,\r\n  requestId?: string\r\n): ErrorResponse {\r\n  return {\r\n    error: {\r\n      code,\r\n      message,\r\n      details,\r\n    },\r\n    request_id: requestId || `req_${Date.now()}_${Math.random().toString(36).substring(7)}`,\r\n    timestamp: new Date().toISOString(),\r\n  };\r\n}\r\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;;AAQO,MAAM,sBAAsB,yKAAC,CAAC,MAAM,CAAC;IAC1C,OAAO,yKAAC,CACL,MAAM,GACN,IAAI,GACJ,GAAG,CAAC,GAAG,yBACP,GAAG,CAAC,KAAK,uCACT,SAAS,CAAC,CAAC,MAAQ,cAAc;IACpC,MAAM,yKAAC,CACJ,MAAM,GACN,GAAG,GACH,QAAQ,GACR,GAAG,CAAC,KAAK,wBACT,OAAO,CAAC,GACR,QAAQ;IACX,WAAW,yKAAC,CACT,MAAM,GACN,GAAG,GACH,QAAQ,GACR,GAAG,CAAC,GACJ,GAAG,CAAC,KAAK,uBACT,OAAO,CAAC,IACR,QAAQ;IACX,SAAS,yKAAC,CACP,MAAM,CAAC;QACN,UAAU,yKAAC,CAAC,MAAM,GAAG,MAAM,CAAC,GAAG,QAAQ;QACvC,MAAM,yKAAC,CAAC,MAAM,GAAG,GAAG,GAAG,EAAE,CAAC,yKAAC,CAAC,MAAM,GAAG,KAAK,CAAC,mCAAmC,QAAQ;QACtF,WAAW,yKAAC,CACT,MAAM,CAAC;YACN,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;YACrC,KAAK,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;QACrC,GACC,QAAQ;IACb,GACC,QAAQ;IACX,SAAS,yKAAC,CACP,MAAM,CAAC;QACN,eAAe,yKAAC,CAAC,OAAO,GAAG,QAAQ;QACnC,aAAa,yKAAC,CAAC,OAAO,GAAG,QAAQ;QACjC,aAAa,yKAAC,CAAC,OAAO,GAAG,OAAO,CAAC,MAAM,QAAQ;IACjD,GACC,QAAQ;AACb;AAKO,MAAM,0BAA0B,yKAAC,CAAC,MAAM,CAAC;IAC9C,GAAG,yKAAC,CACD,MAAM,GACN,IAAI,GACJ,GAAG,CAAC,GAAG,sCACP,GAAG,CAAC,KAAK,kBACT,SAAS,CAAC,CAAC,MAAQ,cAAc;IACpC,OAAO,yKAAC,CAAC,MAAM,GAAG,GAAG,GAAG,QAAQ,GAAG,GAAG,CAAC,IAAI,OAAO,CAAC,IAAI,QAAQ;AACjE;AAKO,MAAM,mBAAmB,yKAAC,CAAC,MAAM,CAAC;IACvC,iBAAiB,yKAAC,CAAC,MAAM,GAAG,IAAI,CAAC;IACjC,QAAQ,yKAAC,CAAC,MAAM,GAAG,IAAI,CAAC;IACxB,UAAU,yKAAC,CAAC,MAAM,GAAG,GAAG,GAAG,QAAQ,GAAG,GAAG,CAAC;IAC1C,KAAK,yKAAC,CAAC,MAAM,GAAG,GAAG,CAAC;IACpB,OAAO,yKAAC,CAAC,MAAM,GAAG,GAAG,CAAC,KAAK,QAAQ;AACrC;AAKO,MAAM,qBAAqB,yKAAC,CAAC,MAAM,CAAC;IACzC,MAAM,yKAAC,CACJ,KAAK,CAAC,yKAAC,CAAC,MAAM,GAAG,GAAG,CAAC,gBACrB,GAAG,CAAC,GAAG,6BACP,GAAG,CAAC,MAAM;IACb,UAAU,yKAAC,CAAC,IAAI,CAAC;QAAC;QAAO;QAAU;KAAO,EAAE,OAAO,CAAC,UAAU,QAAQ;IACtE,gBAAgB,yKAAC,CAAC,OAAO,GAAG,OAAO,CAAC,MAAM,QAAQ;AACpD;AAIA;;;CAGC,GACD,SAAS,cAAc,KAAa;IAClC,oBAAoB;IACpB,IAAI,YAAY,MAAM,OAAO,CAAC,OAAO;IAErC,iEAAiE;IACjE,YAAY,UAAU,OAAO,CAAC,qCAAqC;IAEnE,2BAA2B;IAC3B,YAAY,UAAU,OAAO,CAAC,QAAQ;IAEtC,qCAAqC;IACrC,YAAY,UAAU,IAAI;IAE1B,+DAA+D;IAC/D,MAAM,oBAAoB;QACxB;QACA;QACA;QACA;KACD;IAED,KAAK,MAAM,WAAW,kBAAmB;QACvC,YAAY,UAAU,OAAO,CAAC,SAAS;IACzC;IAEA,OAAO;AACT;AAMO,SAAS,aAAa,IAAY;IACvC,IAAI,CAAC,MAAM,OAAO;IAElB,kBAAkB;IAClB,IAAI,YAAY,KAAK,OAAO,CAAC,YAAY;IAEzC,4BAA4B;IAC5B,YAAY,UACT,OAAO,CAAC,MAAM,SACd,OAAO,CAAC,MAAM,QACd,OAAO,CAAC,MAAM,QACd,OAAO,CAAC,MAAM,UACd,OAAO,CAAC,MAAM,UACd,OAAO,CAAC,OAAO;IAElB,OAAO;AACT;AAKO,SAAS,YAAY,GAAW;IACrC,IAAI;QACF,MAAM,SAAS,IAAI,IAAI;QAEvB,sCAAsC;QACtC,IAAI,CAAC;YAAC;YAAS;SAAS,CAAC,QAAQ,CAAC,OAAO,QAAQ,GAAG;YAClD,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO,OAAO,QAAQ;IACxB,EAAE,OAAM;QACN,MAAM,IAAI,MAAM;IAClB;AACF;AA2BO,SAAS,oBACd,IAAY,EACZ,OAAe,EACf,OAAa,EACb,SAAkB;IAElB,OAAO;QACL,OAAO;YACL;YACA;YACA;QACF;QACA,YAAY,aAAa,CAAC,IAAI,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,IAAI;QACvF,WAAW,IAAI,OAAO,WAAW;IACnC;AACF"}},
    {"offset": {"line": 1484, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/lib/middleware/rate-limit.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\r\nimport { createErrorResponse, RateLimitCheck } from '../validation/schemas';\r\n\r\n/**\r\n * Rate Limiting Middleware\r\n * Implements sliding window rate limiting with in-memory store\r\n * For production, integrate with Redis for distributed rate limiting\r\n */\r\n\r\ninterface RateLimitConfig {\r\n  windowMs: number; // Time window in milliseconds\r\n  maxRequests: number; // Maximum requests per window\r\n  keyGenerator?: (req: NextRequest) => string; // Custom key generator\r\n  skipSuccessfulRequests?: boolean; // Don't count successful requests\r\n  skipFailedRequests?: boolean; // Don't count failed requests\r\n}\r\n\r\ninterface RequestRecord {\r\n  timestamps: number[];\r\n  blockedUntil?: number;\r\n}\r\n\r\nclass RateLimiter {\r\n  private store: Map<string, RequestRecord> = new Map();\r\n  private cleanupInterval: NodeJS.Timeout;\r\n\r\n  constructor() {\r\n    // Cleanup old entries every 5 minutes\r\n    this.cleanupInterval = setInterval(() => {\r\n      this.cleanup();\r\n    }, 5 * 60 * 1000);\r\n  }\r\n\r\n  /**\r\n   * Check if request is allowed under rate limit\r\n   */\r\n  check(key: string, config: RateLimitConfig): RateLimitCheck {\r\n    const now = Date.now();\r\n    const windowStart = now - config.windowMs;\r\n\r\n    // Get or create record\r\n    let record = this.store.get(key);\r\n    if (!record) {\r\n      record = { timestamps: [] };\r\n      this.store.set(key, record);\r\n    }\r\n\r\n    // Check if currently blocked\r\n    if (record.blockedUntil && record.blockedUntil > now) {\r\n      return {\r\n        allowed: false,\r\n        remaining: 0,\r\n        resetAt: new Date(record.blockedUntil),\r\n      };\r\n    }\r\n\r\n    // Remove timestamps outside the window\r\n    record.timestamps = record.timestamps.filter((ts) => ts > windowStart);\r\n\r\n    // Check if limit exceeded\r\n    if (record.timestamps.length >= config.maxRequests) {\r\n      // Block for remaining window time\r\n      const oldestTimestamp = Math.min(...record.timestamps);\r\n      const resetAt = oldestTimestamp + config.windowMs;\r\n      record.blockedUntil = resetAt;\r\n\r\n      return {\r\n        allowed: false,\r\n        remaining: 0,\r\n        resetAt: new Date(resetAt),\r\n      };\r\n    }\r\n\r\n    // Add current request\r\n    record.timestamps.push(now);\r\n\r\n    return {\r\n      allowed: true,\r\n      remaining: config.maxRequests - record.timestamps.length,\r\n      resetAt: new Date(now + config.windowMs),\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Cleanup old entries from store\r\n   */\r\n  private cleanup() {\r\n    const now = Date.now();\r\n    const maxAge = 3600000; // 1 hour\r\n\r\n    for (const [key, record] of this.store.entries()) {\r\n      // Remove if no recent activity and not blocked\r\n      if (\r\n        (!record.blockedUntil || record.blockedUntil < now) &&\r\n        record.timestamps.length === 0\r\n      ) {\r\n        this.store.delete(key);\r\n        continue;\r\n      }\r\n\r\n      // Remove if last activity was over max age\r\n      if (record.timestamps.length > 0) {\r\n        const lastTimestamp = Math.max(...record.timestamps);\r\n        if (now - lastTimestamp > maxAge) {\r\n          this.store.delete(key);\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Reset rate limit for a key\r\n   */\r\n  reset(key: string) {\r\n    this.store.delete(key);\r\n  }\r\n\r\n  /**\r\n   * Shutdown cleanup interval\r\n   */\r\n  destroy() {\r\n    clearInterval(this.cleanupInterval);\r\n  }\r\n}\r\n\r\n// Global rate limiter instance\r\nconst rateLimiter = new RateLimiter();\r\n\r\n/**\r\n * Default rate limit configurations for different endpoints\r\n */\r\nexport const rateLimitConfigs = {\r\n  // Search API: 60 requests per minute per IP\r\n  search: {\r\n    windowMs: 60 * 1000,\r\n    maxRequests: 60,\r\n  },\r\n  // Suggestions API: 120 requests per minute per IP (more lenient for autocomplete)\r\n  suggest: {\r\n    windowMs: 60 * 1000,\r\n    maxRequests: 120,\r\n  },\r\n  // Admin APIs: 10 requests per minute per IP\r\n  admin: {\r\n    windowMs: 60 * 1000,\r\n    maxRequests: 10,\r\n  },\r\n  // Click tracking: 100 requests per minute per IP\r\n  click: {\r\n    windowMs: 60 * 1000,\r\n    maxRequests: 100,\r\n  },\r\n};\r\n\r\n/**\r\n * Get client identifier from request\r\n * Uses IP address, falling back to user-agent if IP unavailable\r\n */\r\nfunction getClientKey(req: NextRequest, prefix: string = 'rl'): string {\r\n  // Get IP address\r\n  const forwarded = req.headers.get('x-forwarded-for');\r\n  const realIp = req.headers.get('x-real-ip');\r\n  const ip = forwarded?.split(',')[0] || realIp || req.ip || 'unknown';\r\n\r\n  // Include user agent for better uniqueness\r\n  const userAgent = req.headers.get('user-agent') || 'unknown';\r\n  const userAgentHash = simpleHash(userAgent);\r\n\r\n  return `${prefix}:${ip}:${userAgentHash}`;\r\n}\r\n\r\n/**\r\n * Simple hash function for strings\r\n */\r\nfunction simpleHash(str: string): string {\r\n  let hash = 0;\r\n  for (let i = 0; i < str.length; i++) {\r\n    const char = str.charCodeAt(i);\r\n    hash = (hash << 5) - hash + char;\r\n    hash = hash & hash; // Convert to 32-bit integer\r\n  }\r\n  return Math.abs(hash).toString(36);\r\n}\r\n\r\n/**\r\n * Rate limit middleware factory\r\n * Creates middleware function with specified configuration\r\n */\r\nexport function createRateLimitMiddleware(config: RateLimitConfig) {\r\n  return async (req: NextRequest): Promise<NextResponse | null> => {\r\n    // Generate rate limit key\r\n    const key = config.keyGenerator?.(req) || getClientKey(req);\r\n\r\n    // Check rate limit\r\n    const result = rateLimiter.check(key, config);\r\n\r\n    // Add rate limit headers\r\n    const headers = new Headers();\r\n    headers.set('X-RateLimit-Limit', config.maxRequests.toString());\r\n    headers.set('X-RateLimit-Remaining', result.remaining.toString());\r\n    headers.set('X-RateLimit-Reset', result.resetAt.toISOString());\r\n\r\n    // If rate limit exceeded, return 429\r\n    if (!result.allowed) {\r\n      const retryAfter = Math.ceil((result.resetAt.getTime() - Date.now()) / 1000);\r\n      headers.set('Retry-After', retryAfter.toString());\r\n\r\n      return NextResponse.json(\r\n        createErrorResponse(\r\n          'RATE_LIMIT_EXCEEDED',\r\n          'Too many requests. Please try again later.',\r\n          {\r\n            limit: config.maxRequests,\r\n            window_ms: config.windowMs,\r\n            retry_after_seconds: retryAfter,\r\n          }\r\n        ),\r\n        {\r\n          status: 429,\r\n          headers,\r\n        }\r\n      );\r\n    }\r\n\r\n    return null; // Allow request to proceed\r\n  };\r\n}\r\n\r\n/**\r\n * Apply rate limiting to a handler function\r\n */\r\nexport function withRateLimit(\r\n  handler: (req: NextRequest) => Promise<NextResponse>,\r\n  config: RateLimitConfig\r\n) {\r\n  return async (req: NextRequest): Promise<NextResponse> => {\r\n    const rateLimitMiddleware = createRateLimitMiddleware(config);\r\n    const rateLimitResponse = await rateLimitMiddleware(req);\r\n\r\n    if (rateLimitResponse) {\r\n      return rateLimitResponse;\r\n    }\r\n\r\n    return handler(req);\r\n  };\r\n}\r\n\r\n/**\r\n * Session-based rate limiting (in addition to IP-based)\r\n * More lenient limits for authenticated users\r\n */\r\nexport function getSessionKey(req: NextRequest): string {\r\n  const sessionId = req.headers.get('x-session-id');\r\n  const userId = req.headers.get('x-user-id');\r\n\r\n  if (userId) {\r\n    return `rl:user:${userId}`;\r\n  } else if (sessionId) {\r\n    return `rl:session:${sessionId}`;\r\n  } else {\r\n    return getClientKey(req);\r\n  }\r\n}\r\n\r\n/**\r\n * Export rate limiter for testing\r\n */\r\nexport { rateLimiter };\r\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;AACA;;;AAqBA,MAAM;IACI,QAAoC,IAAI,MAAM;IAC9C,gBAAgC;IAExC,aAAc;QACZ,sCAAsC;QACtC,IAAI,CAAC,eAAe,GAAG,YAAY;YACjC,IAAI,CAAC,OAAO;QACd,GAAG,IAAI,KAAK;IACd;IAEA;;GAEC,GACD,MAAM,GAAW,EAAE,MAAuB,EAAkB;QAC1D,MAAM,MAAM,KAAK,GAAG;QACpB,MAAM,cAAc,MAAM,OAAO,QAAQ;QAEzC,uBAAuB;QACvB,IAAI,SAAS,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC;QAC5B,IAAI,CAAC,QAAQ;YACX,SAAS;gBAAE,YAAY,EAAE;YAAC;YAC1B,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK;QACtB;QAEA,6BAA6B;QAC7B,IAAI,OAAO,YAAY,IAAI,OAAO,YAAY,GAAG,KAAK;YACpD,OAAO;gBACL,SAAS;gBACT,WAAW;gBACX,SAAS,IAAI,KAAK,OAAO,YAAY;YACvC;QACF;QAEA,uCAAuC;QACvC,OAAO,UAAU,GAAG,OAAO,UAAU,CAAC,MAAM,CAAC,CAAC,KAAO,KAAK;QAE1D,0BAA0B;QAC1B,IAAI,OAAO,UAAU,CAAC,MAAM,IAAI,OAAO,WAAW,EAAE;YAClD,kCAAkC;YAClC,MAAM,kBAAkB,KAAK,GAAG,IAAI,OAAO,UAAU;YACrD,MAAM,UAAU,kBAAkB,OAAO,QAAQ;YACjD,OAAO,YAAY,GAAG;YAEtB,OAAO;gBACL,SAAS;gBACT,WAAW;gBACX,SAAS,IAAI,KAAK;YACpB;QACF;QAEA,sBAAsB;QACtB,OAAO,UAAU,CAAC,IAAI,CAAC;QAEvB,OAAO;YACL,SAAS;YACT,WAAW,OAAO,WAAW,GAAG,OAAO,UAAU,CAAC,MAAM;YACxD,SAAS,IAAI,KAAK,MAAM,OAAO,QAAQ;QACzC;IACF;IAEA;;GAEC,GACD,AAAQ,UAAU;QAChB,MAAM,MAAM,KAAK,GAAG;QACpB,MAAM,SAAS,SAAS,SAAS;QAEjC,KAAK,MAAM,CAAC,KAAK,OAAO,IAAI,IAAI,CAAC,KAAK,CAAC,OAAO,GAAI;YAChD,+CAA+C;YAC/C,IACE,CAAC,CAAC,OAAO,YAAY,IAAI,OAAO,YAAY,GAAG,GAAG,KAClD,OAAO,UAAU,CAAC,MAAM,KAAK,GAC7B;gBACA,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;gBAClB;YACF;YAEA,2CAA2C;YAC3C,IAAI,OAAO,UAAU,CAAC,MAAM,GAAG,GAAG;gBAChC,MAAM,gBAAgB,KAAK,GAAG,IAAI,OAAO,UAAU;gBACnD,IAAI,MAAM,gBAAgB,QAAQ;oBAChC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;gBACpB;YACF;QACF;IACF;IAEA;;GAEC,GACD,MAAM,GAAW,EAAE;QACjB,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;IACpB;IAEA;;GAEC,GACD,UAAU;QACR,cAAc,IAAI,CAAC,eAAe;IACpC;AACF;AAEA,+BAA+B;AAC/B,MAAM,cAAc,IAAI;AAKjB,MAAM,mBAAmB;IAC9B,4CAA4C;IAC5C,QAAQ;QACN,UAAU,KAAK;QACf,aAAa;IACf;IACA,kFAAkF;IAClF,SAAS;QACP,UAAU,KAAK;QACf,aAAa;IACf;IACA,4CAA4C;IAC5C,OAAO;QACL,UAAU,KAAK;QACf,aAAa;IACf;IACA,iDAAiD;IACjD,OAAO;QACL,UAAU,KAAK;QACf,aAAa;IACf;AACF;AAEA;;;CAGC,GACD,SAAS,aAAa,GAAgB,EAAE,SAAiB,IAAI;IAC3D,iBAAiB;IACjB,MAAM,YAAY,IAAI,OAAO,CAAC,GAAG,CAAC;IAClC,MAAM,SAAS,IAAI,OAAO,CAAC,GAAG,CAAC;IAC/B,MAAM,KAAK,WAAW,MAAM,IAAI,CAAC,EAAE,IAAI,UAAU,IAAI,EAAE,IAAI;IAE3D,2CAA2C;IAC3C,MAAM,YAAY,IAAI,OAAO,CAAC,GAAG,CAAC,iBAAiB;IACnD,MAAM,gBAAgB,WAAW;IAEjC,OAAO,GAAG,OAAO,CAAC,EAAE,GAAG,CAAC,EAAE,eAAe;AAC3C;AAEA;;CAEC,GACD,SAAS,WAAW,GAAW;IAC7B,IAAI,OAAO;IACX,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,MAAM,EAAE,IAAK;QACnC,MAAM,OAAO,IAAI,UAAU,CAAC;QAC5B,OAAO,CAAC,QAAQ,CAAC,IAAI,OAAO;QAC5B,OAAO,OAAO,MAAM,4BAA4B;IAClD;IACA,OAAO,KAAK,GAAG,CAAC,MAAM,QAAQ,CAAC;AACjC;AAMO,SAAS,0BAA0B,MAAuB;IAC/D,OAAO,OAAO;QACZ,0BAA0B;QAC1B,MAAM,MAAM,OAAO,YAAY,GAAG,QAAQ,aAAa;QAEvD,mBAAmB;QACnB,MAAM,SAAS,YAAY,KAAK,CAAC,KAAK;QAEtC,yBAAyB;QACzB,MAAM,UAAU,IAAI;QACpB,QAAQ,GAAG,CAAC,qBAAqB,OAAO,WAAW,CAAC,QAAQ;QAC5D,QAAQ,GAAG,CAAC,yBAAyB,OAAO,SAAS,CAAC,QAAQ;QAC9D,QAAQ,GAAG,CAAC,qBAAqB,OAAO,OAAO,CAAC,WAAW;QAE3D,qCAAqC;QACrC,IAAI,CAAC,OAAO,OAAO,EAAE;YACnB,MAAM,aAAa,KAAK,IAAI,CAAC,CAAC,OAAO,OAAO,CAAC,OAAO,KAAK,KAAK,GAAG,EAAE,IAAI;YACvE,QAAQ,GAAG,CAAC,eAAe,WAAW,QAAQ;YAE9C,OAAO,gJAAY,CAAC,IAAI,CACtB,IAAA,qJAAmB,EACjB,uBACA,8CACA;gBACE,OAAO,OAAO,WAAW;gBACzB,WAAW,OAAO,QAAQ;gBAC1B,qBAAqB;YACvB,IAEF;gBACE,QAAQ;gBACR;YACF;QAEJ;QAEA,OAAO,MAAM,2BAA2B;IAC1C;AACF;AAKO,SAAS,cACd,OAAoD,EACpD,MAAuB;IAEvB,OAAO,OAAO;QACZ,MAAM,sBAAsB,0BAA0B;QACtD,MAAM,oBAAoB,MAAM,oBAAoB;QAEpD,IAAI,mBAAmB;YACrB,OAAO;QACT;QAEA,OAAO,QAAQ;IACjB;AACF;AAMO,SAAS,cAAc,GAAgB;IAC5C,MAAM,YAAY,IAAI,OAAO,CAAC,GAAG,CAAC;IAClC,MAAM,SAAS,IAAI,OAAO,CAAC,GAAG,CAAC;IAE/B,IAAI,QAAQ;QACV,OAAO,CAAC,QAAQ,EAAE,QAAQ;IAC5B,OAAO,IAAI,WAAW;QACpB,OAAO,CAAC,WAAW,EAAE,WAAW;IAClC,OAAO;QACL,OAAO,aAAa;IACtB;AACF"}},
    {"offset": {"line": 1686, "column": 0}, "map": {"version":3,"sources":["file:///D:/search-engine-spec/app/api/v1/search/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\r\nimport { hybridSearchService } from '@/lib/services/hybrid-search-service';\r\nimport { interactionService } from '@/lib/services/interaction-service';\r\nimport { queryCounter, queryLatency, queryResultCount } from '@/lib/metrics/prometheus';\r\nimport { searchRequestSchema, createErrorResponse } from '@/lib/validation/schemas';\r\nimport { withRateLimit, rateLimitConfigs } from '@/lib/middleware/rate-limit';\r\n\r\n/**\r\n * Search API endpoint\r\n * POST /api/v1/search\r\n * \r\n * Features:\r\n * - Input validation and sanitization\r\n * - Rate limiting (60 req/min per IP)\r\n * - Hybrid search (Cache → Elasticsearch → PostgreSQL)\r\n * - Comprehensive error handling\r\n * - Metrics collection\r\n */\r\n\r\nasync function searchHandler(req: NextRequest) {\r\n    const startTime = Date.now();\r\n    const requestId = `req_${Date.now()}_${Math.random().toString(36).substring(7)}`;\r\n\r\n    try {\r\n        // Parse and validate request body\r\n        const body = await req.json();\r\n        const validation = searchRequestSchema.safeParse(body);\r\n\r\n        if (!validation.success) {\r\n            queryCounter.inc({ status: 'error', cache_hit: 'false' });\r\n            return NextResponse.json(\r\n                createErrorResponse(\r\n                    'VALIDATION_ERROR',\r\n                    'Invalid request parameters',\r\n                    validation.error.errors,\r\n                    requestId\r\n                ),\r\n                { status: 400 }\r\n            );\r\n        }\r\n\r\n        const { query, page, page_size, filters, options } = validation.data;\r\n\r\n        // Execute hybrid search (Cache → PostgreSQL fallback, skip Elasticsearch)\r\n        const searchStart = Date.now();\r\n        const results = await hybridSearchService.search({\r\n            query,\r\n            page,\r\n            pageSize: page_size,\r\n            filters,\r\n            useCache: true,\r\n            preferElasticsearch: process.env.ENABLE_ELASTICSEARCH === 'true', // Configurable via env\r\n        });\r\n        const executionTime = Date.now() - searchStart;\r\n\r\n        // Log search event\r\n        const sessionId = req.headers.get('x-session-id') || 'anonymous';\r\n        const userId = req.headers.get('x-user-id') || undefined;\r\n\r\n        let eventId = '';\r\n        try {\r\n            eventId = await interactionService.logSearchEvent({\r\n                user_id: userId,\r\n                session_id: sessionId,\r\n                query,\r\n                result_count: results.total_results,\r\n                execution_time_ms: executionTime,\r\n            });\r\n        } catch (err) {\r\n            console.error('Error logging search event:', err);\r\n        }\r\n\r\n        // Record metrics\r\n        queryCounter.inc({ status: 'success', cache_hit: 'false' });\r\n        queryResultCount.observe(results.results.length);\r\n        queryLatency.observe({ stage: 'total' }, (Date.now() - startTime) / 1000);\r\n\r\n        // Add response headers\r\n        const headers = new Headers();\r\n        headers.set('X-Request-ID', requestId);\r\n        headers.set('X-Query-Time-Ms', executionTime.toString());\r\n\r\n        return NextResponse.json(\r\n            {\r\n                ...results,\r\n                meta: {\r\n                    search_event_id: eventId,\r\n                    request_id: requestId,\r\n                },\r\n            },\r\n            { headers }\r\n        );\r\n    } catch (error: any) {\r\n        console.error('Search API error:', error);\r\n        queryCounter.inc({ status: 'error', cache_hit: 'false' });\r\n\r\n        // Determine error type and status code\r\n        let statusCode = 500;\r\n        let errorCode = 'INTERNAL_ERROR';\r\n        let errorMessage = 'An internal server error occurred';\r\n\r\n        if (error.message === 'Search service temporarily unavailable') {\r\n            statusCode = 503;\r\n            errorCode = 'SERVICE_UNAVAILABLE';\r\n            errorMessage = error.message;\r\n        }\r\n\r\n        return NextResponse.json(\r\n            createErrorResponse(\r\n                errorCode,\r\n                errorMessage,\r\n                process.env.NODE_ENV === 'development' ? error.message : undefined,\r\n                requestId\r\n            ),\r\n            { status: statusCode }\r\n        );\r\n    }\r\n}\r\n\r\n// Export with rate limiting\r\nexport const POST = withRateLimit(searchHandler, rateLimitConfigs.search);\r\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AAEA;;;;;;;;;;CAUC,GAED,eAAe,cAAc,GAAgB;IACzC,MAAM,YAAY,KAAK,GAAG;IAC1B,MAAM,YAAY,CAAC,IAAI,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,IAAI;IAEhF,IAAI;QACA,kCAAkC;QAClC,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,aAAa,qJAAmB,CAAC,SAAS,CAAC;QAEjD,IAAI,CAAC,WAAW,OAAO,EAAE;YACrB,8JAAY,CAAC,GAAG,CAAC;gBAAE,QAAQ;gBAAS,WAAW;YAAQ;YACvD,OAAO,gJAAY,CAAC,IAAI,CACpB,IAAA,qJAAmB,EACf,oBACA,8BACA,WAAW,KAAK,CAAC,MAAM,EACvB,YAEJ;gBAAE,QAAQ;YAAI;QAEtB;QAEA,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,OAAO,EAAE,GAAG,WAAW,IAAI;QAEpE,0EAA0E;QAC1E,MAAM,cAAc,KAAK,GAAG;QAC5B,MAAM,UAAU,MAAM,uKAAmB,CAAC,MAAM,CAAC;YAC7C;YACA;YACA,UAAU;YACV;YACA,UAAU;YACV,qBAAqB,QAAQ,GAAG,CAAC,oBAAoB,KAAK;QAC9D;QACA,MAAM,gBAAgB,KAAK,GAAG,KAAK;QAEnC,mBAAmB;QACnB,MAAM,YAAY,IAAI,OAAO,CAAC,GAAG,CAAC,mBAAmB;QACrD,MAAM,SAAS,IAAI,OAAO,CAAC,GAAG,CAAC,gBAAgB;QAE/C,IAAI,UAAU;QACd,IAAI;YACA,UAAU,MAAM,iKAAkB,CAAC,cAAc,CAAC;gBAC9C,SAAS;gBACT,YAAY;gBACZ;gBACA,cAAc,QAAQ,aAAa;gBACnC,mBAAmB;YACvB;QACJ,EAAE,OAAO,KAAK;YACV,QAAQ,KAAK,CAAC,+BAA+B;QACjD;QAEA,iBAAiB;QACjB,8JAAY,CAAC,GAAG,CAAC;YAAE,QAAQ;YAAW,WAAW;QAAQ;QACzD,kKAAgB,CAAC,OAAO,CAAC,QAAQ,OAAO,CAAC,MAAM;QAC/C,8JAAY,CAAC,OAAO,CAAC;YAAE,OAAO;QAAQ,GAAG,CAAC,KAAK,GAAG,KAAK,SAAS,IAAI;QAEpE,uBAAuB;QACvB,MAAM,UAAU,IAAI;QACpB,QAAQ,GAAG,CAAC,gBAAgB;QAC5B,QAAQ,GAAG,CAAC,mBAAmB,cAAc,QAAQ;QAErD,OAAO,gJAAY,CAAC,IAAI,CACpB;YACI,GAAG,OAAO;YACV,MAAM;gBACF,iBAAiB;gBACjB,YAAY;YAChB;QACJ,GACA;YAAE;QAAQ;IAElB,EAAE,OAAO,OAAY;QACjB,QAAQ,KAAK,CAAC,qBAAqB;QACnC,8JAAY,CAAC,GAAG,CAAC;YAAE,QAAQ;YAAS,WAAW;QAAQ;QAEvD,uCAAuC;QACvC,IAAI,aAAa;QACjB,IAAI,YAAY;QAChB,IAAI,eAAe;QAEnB,IAAI,MAAM,OAAO,KAAK,0CAA0C;YAC5D,aAAa;YACb,YAAY;YACZ,eAAe,MAAM,OAAO;QAChC;QAEA,OAAO,gJAAY,CAAC,IAAI,CACpB,IAAA,qJAAmB,EACf,WACA,cACA,uCAAyC,MAAM,OAAO,GAAG,yBACzD,YAEJ;YAAE,QAAQ;QAAW;IAE7B;AACJ;AAGO,MAAM,OAAO,IAAA,qJAAa,EAAC,eAAe,wJAAgB,CAAC,MAAM"}}]
}